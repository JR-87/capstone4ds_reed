---
title: "Predicting Remaining Useful Life of NASA Aircraft Engines "
subtitle: "Using Cox Proportional Hazards Model"
author: "Jayme Reed & Brad Paton (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

[Literature](articleSummaries.html)

## Introduction (take 2)

As the COVID-19 pandemic demonstrated, the ability to predict the
survival of a patient based on their symptoms and medical history is a
major benefit as society deals with health crisis like pandemics. Those
predictions would assist medical practitioners in triage and allow
researchers the ability to generate predictions on the individuals who
are at the greatest risk of losing their lives due to an illness. While
the medical world is the most obvious use of survival predictions, the
same methods can be applied to the predicting bank failure, the
remaining useful life of machines, machinery maintenance timelines, and
insurance likelihood of payouts. There are various survival methods that
can be examined, but this paper will focus on Cox proportional hazards
model. (*don't like)*

Cox proportional hazards (CPH) model is a statistical regression model
for survival modeling that specializes in time-to-event predictions
using using single or multiple covariates and the effects they have on
survival. Traditional regression models struggle to capture the
time-to-event nature of data and treat the time variable as a fixed
value instead of continuous variable. CPH models are able to overcome
those obstacles and are capable of dealing with survival data that
contains censored (events that have not occurred yet in the study
period) data as well. The models also have the advantage of being
semi-parametric which allows more flexibility as compared to other
models.

## Introduction (draft)

Analyzing survival data is challenging for traditional machine learning
models because they struggle to capture the time-to-event nature of the
data. Survival data typically contains challenges difficult to account
for because the datasets may be “censored” meaning that the event hasn’t
had the opportunity to occur yet by the end of the study period. Also,
traditional methods aren’t able to effectively model time-to-event data
because they treat time as fixed values opposed to treating the values
as time leading to less accurate results.

Cox proportional hazards models are commonly used to interpret, analyze,
and examine survival data. These models specialize in time-to-event
predictions and can account for multiple variables and their effects on
survival. Cox proportional hazards models are commonly used in the
health field while predicting patient survivability based on symptoms
and medical history, the financial field to predict bank failure, and
mechanical studies to predict failure of machines. Cox proportional
hazards models are popular due to their ability to incorporate multiple
covariates and they have the advantage of being semi-parametric which
allows more flexibility as compared to other models.

In this paper, we will be examining the prediction of remaining useful
life (RUL) for NASA turbofan jet engines. The lifespan of a jet engine
is important as they cost thousands of dollars to maintain and produce.
The ability to predict the remaining useful lifespan of these engines
will allow for better judgments on the finances needed to maintain or
repair them as well as alert teams that an engine may not have the RUL
for a mission they would like to use it for.

We will first generate the summary statistics for this dataset as well
as run linear and logistic regression tests. We will then test our
assumptions which include the proportional hazards assumption, the
linearity between covariates and the log hazard, that each data is
independent of each other and there is no omitted data. A model will be
generated using the survival package from R. We will then test the model
and make adjustments as needed before generating our predictions.

*Intro guidelines:* The introduction should:

-   Develop a storyline that captures attention and maintains interest.

-   Your audience is your peers

-   Clearly state the problem or question you're addressing.

<!-- -->

-   Introduce why it is relevant needs.

-   Provide an overview of your approach.

Example of writing including citing references:

*This is an introduction to ..... regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The goat study*
[@ziadi2023]*. The insurance[@zapletal2021]*

*This is my work and I want to add more work...*

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
