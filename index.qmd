---
title: "Predicting Survival Probability of NASA Aircraft Engines"
subtitle: "Using Cox Proportional Hazards Model"
author: "Jayme Reed & Brad Paton (Advisor: Dr. Cohen)"
date: last-modified
date-format: long
format:
  html:
    theme: spacelab
    toc: true
    toc-depth: 3
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Slides](slides.html){target="_blank"} \|
[Literature](articleSummaries.html)

```{r, echo = FALSE, warning=FALSE, include=FALSE}
#Load packages
library(tidyverse)
library(gridExtra)
library(grid)
library(survival)
library(survminer)
library(ggpubr)
library(magrittr)
library(ggfortify)
library(knitr)
library(sjPlot)
library(broom)

```

## Introduction

As the COVID-19 pandemic demonstrated, the ability to predict the
survival of a patient based on their symptoms and medical history is a
major benefit as society deals with health crises such as pandemics.
Those predictions would assist medical practitioners in triage and allow
researchers the ability to generate predictions on the individuals who
are at the greatest risk of losing their lives due to an illness. While
the medical world is the most obvious use of survival predictions, the
same methods can be applied to predicting bank failure, the survival
probability of machines, machinery maintenance timelines, and insurance
likelihood of payouts. There are various survival methods that can be
examined, including the Cox proportional hazards model, which will be
examined in this paper.

Cox proportional hazards (CPH) models are statistical regression models
specializing in modeling time-to-event predictions with survival data.
Survival data is data with a value for time and an event
[@Abeysekera2009]. For example, in a study investigating the survival
likelihood of mechanical equipment, the time value would begin when the
equipment begins functioning and would conclude in the event the
equipment stops functioning [@Smith2003]. CPH models can use single or
multiple covariates as a means of creating predictions until failure and
are capable of dealing with survival data that contains censored data as
well [@Seung2023]. Censored data is when the information about an
individual in a study is only known for a certain period of time, such
as the length of the study [@klein2005]. The models also have the
advantage of being semi-parametric, which allows more flexibility as
compared to other models [@Ming-Chiang2014].

As mentioned, CPH is used in various fields, primarily the health
industry, but the usage of the model does not come without challenges. A
COVID-19 study done using data from a Pakistani hospital noted that the
model was limited due to the recovery possibility of COVID-19 patients,
as CPH assumes as time goes on, the survival probability will approach
zero with no survivors. Though CPH was not the best model for this
study, the results of the model were that individuals who were
asymptomatic and young had a higher chance of surviving the virus
[@asghar2024]. In 2024, a study was done in the US on the relationship
between chest pain occurring and mortality of the person experiencing
chest pain using CPH. A response to that study demonstrated the various
limitations of CPH, with the primary concern being the constant hazards
ratio assumption that CPH relies on. In the heart study, the effect of
triglyceride-glucose was assumed to be a constant, but it is actually a
value that fluctuates over time along with an individual's body weight
and blood glucose levels. As such, the model would struggle to predict
correctly the effect of triglyceride-glucose given the violation of the
constant hazards ratio [@jiang2024].

An additional limitation of CPH comes from the data in the covariates
selected and how they can become biased. Two studies done using UK
health data demonstrated how bias can impact the values for the
covariates when relying on patient-submitted information. The first was
a study on the connection between salt intake and the development of
anxiety or depression after 14.5 years [@wang2025], and the second was a
study on the association between postpartum depression and the
development of two or more chronic diseases [@zhang2025]. Both of those
studies relied on patient-submitted health data and survey responses
supplemented with death records and other accessible health records.
This created a possible bias in their data that may have negatively
influenced their model as their collected data may not accurately
reflect the true data. These articles provide examples of the care that
needs to be taken when working with CPH models.

While health care is the dominant field in which CPH is used, a study in
2021 provides an example of using CPH in insurance fields. An insurance
company in the Czech Republic provides policies for certain illness
events, with the insured receiving money when the event occurs, which
concludes the contract. To assist the company with predicting if an
individual will have one of the illness events occur, a model using CPH
was generated using gender, age, and region as the covariates
[@zapletal2021]. A study in 2023 focused on the length of productive
life of female Floridian goats to determine the factors that would
impact the longevity of the goats. CPH was used to determine that both
the age at first birth and the specific herd the female goat belonged to
impacts the length of productive life [@ziadi2023]. Both of these
studies provide examples of the reaches of CPH models outside the health
industry.

While CPH can be applied across various fields for survival probability
modeling, the method does have elements that may limit its accuracy that
must be addressed. Two such elements are the constant hazards ratio and
the censoring of data, as both can lead to limited accuracy. In
addition, the necessity of a time-to-event value within the data source
is something that needs to be considered when choosing to use CPH.
Without that value, using CPH as a survival model will not be the
appropriate method to take with that particular data. This value is also
what makes CPH a prime modeling candidate with health data, as health
metrics frequently have a time component to them. This is frequently
seen when comparing someone over a period of time in a health study, as
is done with medications and the development of cancer or other
illnesses. However, while the usage of CPH is clear in the medical
field, this paper will demonstrate using CPH within the field of
mechanics and survival probability metrics of a machine.

## Methods

### Mathematical Formulas

There are two functions that are the backbone for CPH: the survival
function and the hazard function. The survival function when $X$ is a
continuous random variable is

$$
S(x) = 1 - F(x) = 1 - Pr(X > x) = \int_x^\infty f(x) dx
$$ {#eq-survival}

where $S(x)$ is the probability that an individual has survived past
time $x$ [@klein2005].

The hazard function, which is also known as the hazard rate function,
can be defined as

$$
 h(x) = \lim_{\Delta x \rightarrow 0} \frac{P[x\leq X < x + \Delta x | X \geq x]}{\Delta x}
$$ {#eq-hazardrate}

The function is used to describe how the chance of experiencing the
event changes with time and only has the requirement of being
non-negative [@klein2005].

CPH then uses both functions to develop its own model, specifically by
adapting the hazard function. Since CPH is a proportional hazard model,
the hazard function is adapted to deal with the relationship between
time to event and the explanatory variables [@klein2005]. It can be
defined as

$$
h(t|\mathbf{Z} ) = h_0(t)\text{exp}(\sum_{k=1}^p \beta_kZ_k)
$$ {#eq-coxhazard}

where,

-   $h(t|\mathbf{Z})$ is the hazard rate at time $t$ for an subject with
    risk vector $\mathbf{Z}$
-   $h_0(t)$ is a baseline hazard rate when all covariates are $0$
-   $\text{exp}(\sum_{k=1}^p \beta_k Z_k)$ is a semi-parametric model
-   $\beta_k$ is a parameter vector
-   $Z_k$ is the risk vector [@klein2005]

CPH is considered a proportional hazards model due to the hazard ratio
between two individuals being a constant value. The ratio of the hazard
function for an individual with $\mathbf{Z}$ covariates where
$Z_k = z+1$ and for an individual with $\mathbf{Z}^*$ covariates where
$Z_k = z$ with all other predictors fixed [@nahhas2025] is defined as

$$
\frac{h(t|\mathbf{Z})}{h(t|\mathbf{Z}^*)} = \frac{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z_k]}{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z^*_k]} = \text{exp}[\sum_{k=1}^p \beta_k(Z_k - Z_k^*)]
$$ {#eq-hazardratio}[@klein2005]. The result of the hazard ratio (HR) is
a constant that implies an association between a continuous predictor
and the outcome. The interpretation of the HR is

-   if HR $> 1$ implies a positive association such that
    $100\% \times (HR - 1)$ is the \\% of greater risk for $Z = z+1$
    when compared to $Z = z$.
-   if HR $< 1$ implies a negative association such that
    $100\% \times (HR -1)$ is the \\% of decreased risk for $Z = z+1$
    when compared to $Z= z$.
-   if HR $=1$ implies no association. [@nahhas2025]

An additional useful equation is the cumulative hazard function. The
cumulative hazard function can be defined as

$$
\begin{align*}
 H(x) = \int_0^x h(u) du 
\end{align*}
$$ {#eq-cumulativehr}

where $h(u)$ is the hazard rate function [@klein2005]. This function
provides a better understanding of the survival function for graphing
purposes.

### Covariate Selection

Depending on the study, there will be covariates that do not impact the
probability of survival. Statistical methods such as the Wald test can
be used to determine which ones are statistically significant
individually and may have an impact in a multivariate model. Generating
a univariate CPH model for each covariate and using the Wald test with a
significance level of $\alpha = 0.05$ will allow for determination of if
a covariate is significant. Additional tests for models will involve
using a stepwise regression and comparing the results based on the
assumptions that are met and the concordance index. Any covariates that
are determined to be not significant to the survival probability can be
removed from the final CPH model.

### Assumptions

```{r, echo = FALSE}
#generation of the model for sample plots
example_surv_object <- Surv(time = lung$time, event = lung$status)

example_coxmodel <- coxph(example_surv_object ~ meal.cal, data = lung)
```

There are four assumptions that a CPH model must meet in order to be an
accurate model. For any violation of those assumptions, the data will
need to be either transformed, stratified, or other covariates may need
to be selected for the model. The four assumptions are the independence
assumption, non-informative censoring, linearity assumption, and
proportional hazards assumption.

**Independence Assumption**

CPH assumes that the survival times of observed subjects are independent
of each other. This is similar to most regression models, though CPH
does not assume that the residuals of the model are normally distributed
or have constant variance [@nahhas2025].

**Non-informative Censoring Assumption**

CPH assumes that censoring is non-informative, which means that each
subject has the same risk of experiencing the event regardless of one of
them being censored. Thus, the knowledge of censoring does not result in
any new information being provided [@nahhas2025].

**Linearity Assumption**

CPH assumes the relationship between covariates and the outcome is a
linear relationship [@nahhas2025]. For CPH, the outcome for that
relationship is the log of the hazard rate. This assumption is checked
visually using the Martingale residuals for each covariate
[@nahhas2025]. Martingale residuals are a type of residual used in
survival analysis that shows the discrepancy between the observed and
the expected number of events. The equation is $$
\begin{align*}
\text{Martingale Residuals} = \text{Observed Events} - \text{Expected Events}
\end{align*}
$$

The resulting residuals are examined visually, and if they are linear
and appear to have a slope of zero, the linearity assumption is not
violated [@Amini2015]. If a model is being generated with multiple
covariates, multiple Martingale residual plots will need to be generated
in order to verify this assumption for each covariate.

Below is an example plot showing Martingale residuals plotted for a
covariate being tested. From the plot, it is visually clear that the
residuals are linear and appear to have a slope of zero. For this
covariate, the linearity assumption has not been violated.

```{r,echo=FALSE}
example_martingale <- resid(example_coxmodel, type = "martingale")

plot(example_martingale, 
     main = "Martingale Residuals: Example Covariate",
     ylab = "Martingale Residuals for Example Covariate",
     xlab = "Value Range for Example Covariate")
abline(h = 0, col = "red")
```

**Proportional Hazards Assumption**

The major assumption for CPH is the proportional hazards (PH)
assumption, which states that the ratio of hazard rates for any two
subjects must be constant at all times. This means the effect of the
covariates must be constant over time [@Bustan2018]. To test this
assumption, the hypothesis test below is used: $$
\begin{align*}
H_0&: \text{the log hazard ratio for each covariate remains constant over time.} \\
H_1&: \text{the log hazard ratio for each covariate does not remain constant over time}
\end{align*}
$$

To generate the p-value for the hypothesis test, the scaled Schoenfeld
partial residuals are calculated for each covariate. The Schoenfeld
partial residuals are the difference between the value of the covariate
and the expected value of the covariate at the time of failure
[@klein2005]. If the global p-value is $< 0.05$, then the model has at
least one covariate that violates the PH assumption, and each individual
covariate p-value will need to be checked. If the global p-value is
$> 0.05$, then the PH assumption holds for all covariates [@nahhas2025].
To visually confirm the PH assumption, the plot of the scaled Schoenfeld
partial residuals for each covariate should be a horizontal line
[@harrison2021].

Violations of the PH assumption can be dealt with in several ways. If
the covariate is categorical, one way is to stratify the covariate,
which will generate a separate baseline hazard function for each level
of the covariate [@harrison2021]. This removes the PH assumption for
that covariate, though it will still be assumed for all other covariates
in each level of the stratification [@nahhas2025]. If the covariate is
continuous, one way is to add in a function of time based on the shape
of the hazard ratio plot. This replaces the model's time coefficient
with a function of time as it assumes the covariate varies either
linearly or non-linearly with time [@nahhas2025].

Below is an example plot demonstrating scaled Schoenfeld partial
residuals plotted against time to test the proportional hazards
assumption. While there is some curvature in the line, the residuals are
roughly horizontal, indicating proportional hazard over time for this
covariate.

```{r, echo = FALSE}
example_phtest <- cox.zph(example_coxmodel)

plot(example_phtest[1],
     ylab = "Covariate Schoenfeld Residual",
     xlab = "Time")
```

Below is an example of the global value that can be generated for the
whole model. In comparing it with an $\alpha = 0.05$, the covariate does
not meet the proportional hazards assumption as $p = 0.128 < \alpha$ .
However, individually, meal.cal does meet the assumption as
$p = 0.044 < \alpha$ . As such, age would need to be adapted based on
one of the above methods in order to include it in the model.

```{r, echo=FALSE}
multi <- coxph(example_surv_object ~ meal.cal + age, data = lung)
ph_tibble <- cox.zph(multi) %>%
  pluck("table") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  as_tibble()
kable(ph_tibble, format = "markdown")
```

### Model Visualization

Two common model visualizations used for CPH are the forest plot and the
Kaplan-Meier survival curve. The Kaplan-Meier curve assists in
visualizing the initial survival model for the data, while the forest
plot assists in visualizing the hazard ratio after generating a model.

**Kaplan Meier Survival Curve**

The Kaplan-Meier (KM) estimator is also known as the Product-Limit
estimator and was proposed by Kaplan and Meier in 1958. The estimator
can be defined as

$$
\hat{S}(t) = \begin{cases}
1 \qquad \qquad \qquad \: \text{if } \; t< t_1,\\
\prod_{t_\leq t}[1 - \frac{d_j}{Y_i}], \quad\text{if} \; t_1 \leq t
\end{cases}
$$ {#eq-km} where,

-   $d_i$ is the number of events at time $t_i$
-   $Y_i$ is the number of individuals who are risk at time $t_i$
    [@klein2005]

KM is a non-parametric estimate, which means it makes no assumption of
the shape of the base survival function [@nahhas2025] and is considered
to be well defined up until the largest observed study time, $t_{max}$
[@klein2005]. The survival curve provides a visualization of the KM
estimator and is important when modeling survival data because it
demonstrates the time when the event being modeled is expected to occur.

Below is an example survival curve showing survival probabilities over
time. The line represents the median survival probability, with the red
area around it showing the 95% confidence interval for the values. The
curve can be interpreted as showing the probability of an event that
would be expected to happen around a time of 300, where the survival
probability is below 50% [@Kuitunen2021].

```{r, echo=FALSE}
example_curve <- survfit(example_coxmodel)

ggsurvplot(example_curve,
           data = lung,
           title = "Example Survival Curve",
           xlab = "Time",
           ylab = "Survival Probability",
           legend = "none")
```

**Forest Plots**

Forest plots can be used to visualize the effects each covariate in the
model has on the hazard ratio. The resulting plot contains each
covariate on the y-axis, with the estimated effect on the hazard ratio
on the the x-axis. The plot contains whiskers demonstrating a 95%
confidence interval for the effect. A positive effect indicates a
positive correlation with the hazard ratio, where the higher the number
is, the more severe the effect on the hazard ratio.

An example forest plot is shown below, plotting the hazard ratio for
each covariate in the model. The point represents the calculated hazard
ratio, and the whiskers show the 95% confidence interval.

```{r, echo=FALSE,warning=FALSE}
forest <- coxph(example_surv_object ~ age + sex, data = lung)

plot_model(forest,
           dot.size = 1,
           line.size = 1,
           colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")

```

### Evaluation

Evaluation of the accuracy of the CPH model is done using the
concordance index, which is used to measure the amount of agreement
between two variables. Specifically, the value looks at concordant pairs
and discordant pairs. A concordant pair is when either $x_i < x_j$ and
$y_i < y_j$ or $x_i > x_j$ and $y_i > y_j$. A discordant pair is when
either $x_i$ or $y_i$ are not in the same place, such as $x_i < x_j$ but
$y_j < y_i$ [@Therneau2017]. In terms of survival, this can be thought
of as examining when the failure event occurs. If two subjects, A and B,
are compared, with subject A having a higher risk, the pair would be
considered concordant if subject A does have the failure event occur
before subject B.

The equation for concordance with CPH is

$$
C =\frac{c + \frac{t_x}{2}}{c + d + t_x}
$$ {#eq-concordance}

where,

-   $c$ is the count of pairs that are concordant
-   $d$ is the count of pairs that are discordant
-   $t_x$ are the pairs tied to the predictor $x$ [@Therneau2017]

The concordance index will produce a value between 0 and 1. A value of 1
means all pairs are correctly ordered, and a value of 0 means none of
the pairs are correctly ordered. Any values between 0 and 1 indicate how
accurate the CPH model is with the data [@Therneau2017].

### Survival Probability

CPH can be used to predict the survival probability at a specific time
$S(t|X=x)$, and the hazard ratio for an individual when compared to a
reference individual $\frac{h(t|X=x)}{h(t|X=x_{ref}}$ [@nahhas2025]. The
equation is

$$
S(t) = e^{-H(t)}
$$ {#eq-survprob}

where, $H(t)$ is the cumulative hazard up to time $t$.

If the resulting probability is greater than or equal to 50%, it is
assumed the event has not occurred. If the resulting probability is less
than 50%, it is assumed the event has occurred. It is also possible to
generate a plot of the estimated survival curves for all values of $t$
that are desired. However, CPH is not able to predict the specific time
the event is going to occur, which is considered a limitation of the
model.

## Analysis and Results

### Data Structure, Exploration, and Visualization

Though CPH is typically used with health data, it does have applications
in other fields. This paper will study the survival probability of a
NASA aircraft engine using data provided by NASA for the study on
propagation modeling [@saxena2008]. In particular, this paper will be
examining the data from the engine design two, which has a training
dataset and a testing dataset.

**Data Structure**

Each engine in the NASA data has an unknown amount of wear,
manufacturing variation, and sensor noise, which will impact the
survival time. In the training dataset, each engine is operating
normally at the beginning of the time series, will develop a fault, and
experience failure at some point. All engines will have failed in the
training dataset. The conditions the engines are subjected to are
represented by three operational setting fields and twenty-one sensor
measurement fields. In the testing dataset, none of the engines have
experienced failure [@saxena2008].

A column indicating status is needed for both the training and testing
datasets. The value 0 will be used to indicate if the machine is still
working and the value 1 will be used for the last cycle before the
engine fails. Both values will appear in the training dataset as all
engines in that dataset will eventually fail. The testing dataset will
only have the value of 0, as none of the machines have failed in that
dataset.

The table below shows the structure for the combined training and
testing data after the transformations described above.

```{r}
testurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/test_FD002.txt'

test <- read.delim(testurl, header = TRUE, sep = '') %>%
  mutate(status = 0,
         id = id + 260)

trainurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/train_FD002.txt'

train <- read.delim(trainurl, header = TRUE, sep = '') %>%
  group_by(id) %>%
  mutate(status = if_else(row_number() == n(), 1, 0)) %>%
  ungroup() 

data_all <- rbind(train, test) 


kable(head(data_all, n = 5), format = "markdown", caption = 'NASA Aircraft Engine Data')
```

**Data Visualization**

There are 519 engines in the combined data, with 260 engines in the
training data and 259 engines in the testing data. The below metrics are
generated using the training data, as that data contains no censored
data. The histogram shows that the survival times of the engines are
normally distributed, and the box plot shows there are six outliers in
the dataset. The engines have a median survival time of 199 cycles with
a standard deviation of 46.78. The maximum number of cycles an engine
lasted was 378, while the minimum number of cycles an engine lasted was
128. Since the testing data contains all censored data, the basic
metrics were not generated.

```{r}
train_grouped <- train %>% 
  group_by(id) %>%
  slice_max(time)

data_grouped <- data_all %>%
  group_by(id) %>%
  slice_max(time) 


summarymetrics <- data.frame(c("Minimum", "Median", "Mean", "Standard Deviation", "Maximum"),
                             c(min(train_grouped$time), 
                               median(train_grouped$time),
                               mean(train_grouped$time),
                               sd(train_grouped$time),
                               max(train_grouped$time)))

colnames(summarymetrics) <- c("Metric", "Value")
summarymetrics$Value <- round(summarymetrics$Value, digits = 2)
kable(summarymetrics, format = "markdown", align = "c")

```

```{r, echo=FALSE}
Histogram <- ggplot(data = train_grouped,
       aes(x = time)) +
  geom_histogram(binwidth = 5,
                 fill = "grey")+
  labs(x = "Survival Time (Iterations)",
       y = "Frequency")+
  theme_bw()

box <- ggplot(data = train_grouped,
                  aes(y = time))+
  geom_boxplot(fill = "gray",
               color = "black")+
  ylab("Time (Iterations)")+
  theme_bw()


grid.arrange(Histogram,box,ncol = 2, top = "Distribution of Engine Longevity in Training Data")

```

To determine the initial survival function, using the training data, the
Kaplan-Meier survival curve was generated and is shown below. The graph
visualizes the survival curve and the information that was gathered
through the histogram.

```{r}
t <- as.matrix(train_grouped[, "time"])
s <- as.matrix(train_grouped[, "status"])

km_fit <- survfit(Surv(t, s) ~ 1)

autoplot(km_fit) + theme_bw()
```

### Creating Cox Proportional Hazards Model

**Generating Models**

Generation of the CPH models will be done using R, specifically the R
package `survival`. To generate the CPH model with properly formatted
survival data, a survival object is created by running
`Surv(time, event)`, where `time` is the time field and `event` is the
event field. To generate the actual model, the survival object is then
applied to the function `coxph(survival object ~ x, data)`, where `x`
represents the covariate(s) and `data` is the survival data that is
being modeled [@R-base].

Based on the information provided by NASA on their data, there are
various sensors and operational setting fields that do not impact the
survival rate of an engine. To determine which covariates are
statistically significant, the below univariate test was run. The test
uses the Wald test to determine which covariates will significantly
impact the model individually. The covariates in which the p-value is
$< 0.05$ will be considered statistically significant.

```{r}
covariates <- c("os1", "os2", "os3", "sm1", "sm2", "sm3", "sm4", "sm5", "sm6", "sm7",
                "sm8", "sm9", "sm10", "sm11", "sm12", "sm13", "sm14", "sm15", "sm16",
                "sm17", "sm18", "sm19", "sm20", "sm21")

univ_formulas <- sapply(covariates,
                        function(x) as.formula(paste('Surv(time, status)~', x)))

univ_models <- lapply( univ_formulas, function(x){coxph(x, data = data_grouped)})

# Extract data
univ_results <- lapply(univ_models,
                       function(x){
                          x <- summary(x)
                          p.value<-signif(x$wald["pvalue"], digits=2)
                          wald.test<-signif(x$wald["test"], digits=2)
                          beta<-signif(x$coef[1], digits=2);#coefficient beta
                          HR <-signif(x$coef[2], digits=2);#exp(beta)
                          HR.confint.lower <- signif(x$conf.int[,"lower .95"], 2)
                          HR.confint.upper <- signif(x$conf.int[,"upper .95"],2)
                          HR <- paste0(HR, " (",
                                       HR.confint.lower, "-", HR.confint.upper, ")")
                          res<-c(beta, HR, wald.test, p.value)
                          names(res)<-c("beta", "HR (95% CI for HR)", "wald.test",
                                        "p.value")
                          return(res)
                         })
kable(as.data.frame(univ_results))
```

Based on the above test, none of the covariates are statistically
significant individually with all the data. As such, to determine the
best model to use for this analysis, a forward and backward stepwise
regression will be done to generate the models with the best Akaike
Information Criterion (AIC) and Bayesian Information Criterion (BIC)
values. This method produced three possible models. The fourth model in
the below table used covariates that were determined to significant with
the training data only.

The table below provides the model number, the covariates used, the AIC
and BIC from the stepwise regression if applicable, and the concordance
index. After determining the most accurate model, the CPH assumptions
will be tested.

```{r}
surv_object <- Surv(data_grouped$time, data_grouped$status)

all_cov <- coxph(data = data_grouped, surv_object ~ os1 + os2 + os3 + sm1 + sm2 + sm3 + sm4 + sm5 + sm6 + sm7 + sm8 + sm9 + sm10 + sm11 + sm12 + sm13 + sm14 + sm15 + sm16 + sm17 + sm18 + sm19 + sm20 + sm21)

aic <- MASS::stepAIC(all_cov, trace = 0)
n <- nrow(data_grouped)
bic <- step(all_cov, direction = "both", k = log(n), trace = 0)


cox1 <- coxph(data = data_grouped, surv_object ~ os1 + os2 + os3 + sm1 + sm2 + sm3 + sm4 + sm5 + sm6 + sm7 + sm8 + sm9 + sm10 + sm11 + sm12 + sm13 + sm14 + sm15 + sm16 + sm17 + sm18 + sm19 + sm20 + sm21)

cox2 <- coxph(data = data_grouped, surv_object ~ os3 + sm3 + sm4 + sm5 + sm8 + sm9 + sm15 + sm16 + sm17 + sm18 + sm20)

cox3 <- coxph(data = data_grouped, surv_object ~ os3 + sm3 + sm4 + sm8 + sm9 + sm15 + sm18)

cox4 <- coxph(data = data_grouped, surv_object ~ os3 + sm13 + sm14 + sm19)


```

```{r, echo = FALSE}
stepwise_results <- data.frame(c("model 1", "model 2", "model 3", "model 4"), 
                               c("All covariates", "os3, sm3 - sm5, sm8 - sm9, sm15 - sm18, sm20", "os3, sm3 - sm4, sm8-sm9, sm15, sm18", "os3, sm13 - sm14, sm19"),
                               c("2449.92", "2431.88", "N/A", "N/A"),
                               c("2547.71", "N/A", "2461.31", "N/A"),
                               c(cox1$concordance[6], cox2$concordance[6], cox3$concordance[6], cox4$concordance[6]))

colnames(stepwise_results) <- c("Model", "Covariates", "AIC", "BIC", "Concordance")


kable(stepwise_results, format = "markdown")

```

In determining the best model for this data, it was determined that CPH
is not the survival method that should be used on this data. By stepwise
regression, the models with the lowest BIC and AIC should have been used
in the following analysis; however, both models continuously failed the
CPH assumptions. As such, the model for the following analysis will be
model 1, which contained all covariates and had the highest concordance
value.

While model 1 does have initially contain all 24 covariates, there are
two that will need to be removed before proceeding with the analysis due
to infinite coefficients and linearly dependence. The covariate sm19 is
linearly dependent on another value, and the covariate sm16 resulted in
a possible infinite coefficient. The following analysis will be done
using model 1 without sm16 and sm19. The below tables provide the
summary values from the model.

```{r}
cox1.1 <- coxph(data = data_grouped, surv_object ~ os1 + os2 + os3 + sm1 + sm2 + sm3 + sm4 + sm5 + sm6 + sm7 + sm8 + sm9 + sm10 + sm11 + sm12 + sm13 + sm14 + sm15 + sm17 + sm18 + sm20 + sm21)

ci <- cox1.1$concordance[6]
```

```{r, echo = FALSE}
kable(tidy(cox1.1), format = "markdown")

g <- glance(cox1.1)
g <- g %>% select(n, nevent, concordance, std.error.concordance, logLik, statistic.log, p.value.log, statistic.wald, p.value.wald, statistic.sc, p.value.sc)

kable(g, format = "markdown")
```

The forest plot for model 1 is shown below. The covariates that are
closest to the value of one have a hazard rate that has less effect on
the calculated hazard ratio for the entire model.

```{r, echo = FALSE}
plot_model(cox1.1,
           dot.size = 2,
           line.size = 1,
           colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")
```

### Checking Assumptions

After determining the model to use with the covariates, the CPH
assumptions need to be tested to confirm the model is a valid CPH model.
The model may have a high concordance index, but it may not be valid for
CPH to use to predict the survival probability. If any of the
assumptions for the model are not met, the model will need to be
modified.

**Independence Assumption**

The survival times for each individual engine in the data are
independent of each other. The failure of one engine does not impact the
failure of another, so this assumption is met.

**Non-informative Censoring Assumption**

While the data that was pulled from the training set does not include
censored data, all of the data from the testing dataset is censored, as
those engines had not experienced failure in the study time period.
However, it is known that those engines will experience failure at some
point, and knowing those engines are censored does not provide any new
information. As such, this assumption is met.

**Linearity Assumption**

To check the linearity assumption, the residuals of the model are
needed, which can be generated using the `resid` function in R and
assigning the type to be martingale (`resid(type = "martingale")` ).
This will create a vector of residuals that can be plotted against the
range of values for each covariate.

The plots of the Martingale residuals versus the range of values for
each covariate are shown below. For each covariate, there is no clear
slope indicating the linearity assumption is true for the covariates in
the model.

```{r}
martingale <- resid(cox1.1, type = "martingale")
```

```{r, echo = FALSE}
par(mfrow = c(4,4),
      mar = c(2,2,4,1))

plot(data_grouped$os1, martingale, main = "Martingale Residuals: os1")
abline(h = 0, col = "red")

plot(data_grouped$os2, martingale, main = "Martingale Residuals: os2")
abline(h = 0, col = "red")

plot(data_grouped$os3, martingale, main = "Martingale Residuals: os3")
abline(h = 0, col = "red")

plot(data_grouped$sm1, martingale, main = "Martingale Residuals: sm1")
abline(h = 0, col = "red")

plot(data_grouped$sm2, martingale, main = "Martingale Residuals: sm2")
abline(h = 0, col = "red")

plot(data_grouped$sm3, martingale, main = "Martingale Residuals: sm3")
abline(h = 0, col = "red")

plot(data_grouped$sm4, martingale, main = "Martingale Residuals: sm4")
abline(h = 0, col = "red")

plot(data_grouped$sm5, martingale, main = "Martingale Residuals: sm5")
abline(h = 0, col = "red")

plot(data_grouped$sm6, martingale, main = "Martingale Residuals: sm6")
abline(h = 0, col = "red")

plot(data_grouped$sm7, martingale, main = "Martingale Residuals: sm7")
abline(h = 0, col = "red")

plot(data_grouped$sm8, martingale, main = "Martingale Residuals: sm8")
abline(h = 0, col = "red")

plot(data_grouped$sm9, martingale, main = "Martingale Residuals: sm9")
abline(h = 0, col = "red")

plot(data_grouped$sm10, martingale, main = "Martingale Residuals: sm10")
abline(h = 0, col = "red")

plot(data_grouped$sm11, martingale, main = "Martingale Residuals: sm11")
abline(h = 0, col = "red")

plot(data_grouped$sm12, martingale, main = "Martingale Residuals: sm12")
abline(h = 0, col = "red")

plot(data_grouped$sm13, martingale, main = "Martingale Residuals: sm13")
abline(h = 0, col = "red")

plot(data_grouped$sm14, martingale, main = "Martingale Residuals: sm14")
abline(h = 0, col = "red")

plot(data_grouped$sm15, martingale, main = "Martingale Residuals: sm15")
abline(h = 0, col = "red")

plot(data_grouped$sm17, martingale, main = "Martingale Residuals: sm17")
abline(h = 0, col = "red")

plot(data_grouped$sm18, martingale, main = "Martingale Residuals: sm18")
abline(h = 0, col = "red")

plot(data_grouped$sm20, martingale, main = "Martingale Residuals: sm20")
abline(h = 0, col = "red")

plot(data_grouped$sm21, martingale, main = "Martingale Residuals: sm21")
abline(h = 0, col = "red")
```

**Proportional Hazards Assumption**

The `cox.zph` function can be used to check the proportional hazards
assumption. As mentioned, the function calculates p-values for each
covariate. The global p-value will first be compared to $\alpha = 0.05$.
If that p-value is $<\alpha$, then at least one covariate violates the
PH assumption, and the model will need to be adapted.

The output below shows the p-values for the hypothesis test and
Schoenfeld residuals. The global p-value is $> \alpha$ so none of the
covariates violates the PH assumption on a global level. Examining each
individual covariate through both p-values and the plot of the
Schoenfeld residuals does show that os1, os3, sm13, and sm14 violate the
PH assumption. However, since the global p-value does show that the
model itself meets the PH assumption, the analysis will proceed with
those covariates. If the global p-value had not met the assumption,
further analysis of those four covariates would need to be completed in
order to met the PH assumption.

```{r}
cph_ph <- cox.zph(cox1.1) %>%
  pluck("table") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  as_tibble()
kable(cph_ph, format = "markdown")
```

```{r, echo = FALSE}
# Function to put ph_plots on one visual
create_ph_plots <- function(coxmodel, row, col){
  # Function takes argument that is a cox model from coxph()
  
  phresults <- cox.zph(coxmodel)

  # Define dimensions of visual
  par(mfrow = c(row, col),
      mar = c(2,2,4,1))


  # Loop through each covariate creating a plot and adding it to the phplot list
  for (i in 1:(length(phresults$table[,1])-1)){
    phplots <- list()
    phplots[i] <- plot(phresults[i], # Create plot for each iteration
                       main = rownames(phresults$table)[i]) # Title of each plot is the rowname from coxmodel$table
  
  }
  mtext("Schoenfeld Residuals vs. Time for Covariates", side = 3, line = -1.5, outer = TRUE, cex = 1) # Title for Visual
  par(mfrow = c(1,1)) # Reset plotting area
}

create_ph_plots(cox1.1, 3, 5)
```

### Model Results

**Evaluation**

The CPH model that was selected has a concordance value of
`{r} round(ci, 2)`, which indicates that it is more than 50% accurate in
predicting the survival of the machines. However, this model is not
completely accurate, so there is an expectation of some error in the
model survival probabilities which will lead to caution in providing
results in application settings.

**Calculations**

The CPH model created produced coefficients for each covariate
indicating the quantitative effect on the resulting hazard rate. The
coefficients are shown below.

```{r}
coef <- data.frame(CoefficientValue = cox1.1$coefficients)
kable(coef, format = "markdown")
```

The coefficients above can be used to calculate the hazard rate
([@eq-hazardrate]), the cumulative hazard value ([@eq-cumulativehr]),
and the survival probability ([@eq-survprob]). The hazard rate at time
$t$ will be calculated for each engine at the engine's max time value.
The cumulative hazard value is the total hazard accumulated for the
subject over time and is used to estimate the risk for the subject at a
point in time. The engines that have higher hazard rates or higher
cumulative hazard values are at a greater risk of experiencing failure.
The below table provides the hazard rate and survival probability for
the first 10 engines in the dataset.

```{r}
data_grouped_reduced <- data_grouped %>% select(id, time, os1, os2, os3, sm1, sm2, sm3, sm4, sm5, sm6, sm7, sm8, sm9, sm10, sm11, sm12, sm13, sm14, sm15, sm17, sm18, sm20, sm21, status)


data_grouped_reduced$HazardRate <- predict(cox1.1,
        newdata = data_grouped_reduced,
        type = "risk")

data_grouped_reduced$SurvivalProbability <- predict(cox1.1, type = "survival", newdata = data_grouped_reduced)

print_data <- data_grouped_reduced %>% select(id, time, status, HazardRate, SurvivalProbability)

kable(head(print_data, n = 10), format = "markdown")
```

The below graphs demonstrate the cumulative hazard over time and the
survival curve from the prediction model.

```{r, echo = FALSE}
sf <- survfit(cox1.1)

ggsurvplot(fit = sf,
           data = data_grouped_reduced, risk.table = TRUE, fun = "cumhaz")$plot +
  ggtitle('Cumulative Hazard Over Time')

```

```{r, echo = FALSE}
survtimes <- data.frame(Percent = c("100% Survival", "75% Survival,", "50% Survival", "25% Survival", "10% Survival"),
                        Time = c(sf$time[sf$lower < 1][1], 
                                    sf$time[sf$lower < .75][1], 
                                    sf$time[sf$lower < .5][1], 
                                    sf$time[sf$lower < .25][1], 
                                    sf$time[sf$lower < .1][1]))

ggsurvplot(fit = sf, data = data_grouped_reduced)$plot +
  ggtitle('Survival Probability Over Time')

```

## Conclusion

The implications of an engine failure are severe, as failure can lead to
injury or death and the loss of millions of dollars. As such,
understanding when an engine will fail allows for maintenance to occur
before negative impacts occur. While CPH does not allow for the
prediction of specific failure times, it does allow for the creation of
confidence intervals, which can be used to gain an understanding of when
engines are most likely to fail. The table below displays the percent of
survival at the lower end of the confidence interval to exercise
caution.

```{r}
kable(survtimes, format = "markdown")

```

The lower end of the confidence interval for survival probability is
shown to hold stable at 100% until `t = 128`, with a gradual decrease
afterwards. Half of the engines are expected to survive until `t = 245`,
and 90% of the engines are expected to fail at `t = 347`. These results
can be viewed in both the above survival graph and the cumulative hazard
plot which shows a low hazard until `t = 128` with a gradual increase.

Based on these findings, the model can be applied by recommending that
NASA not use engines after 128 iterations have passed. The engines
should undergo routine maintenance beforehand and should be evaluated to
ensure the probability of survival calculated by the model remains at
100%. All engines should be equipped with sensors for the covariates
used, and readings should be applied to the model after each use of the
engine. The engine should be removed from service if the resulting
survival probability is less than 100%.

## References
