---
title: "Predicting Remaining Useful Life of NASA Aircraft Engines"
subtitle: "Using Cox Proportional Hazards Model"
author: "Jayme Reed & Brad Paton (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    theme: spacelab
    toc: true
    toc-depth: 3
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Slides](slides.html){target="_blank"} \|
[Literature](articleSummaries.html)

## Introduction

As the COVID-19 pandemic demonstrated, the ability to predict the
survival of a patient based on their symptoms and medical history is a
major benefit as society deals with health crises such as pandemics.
Those predictions would assist medical practitioners in triage and allow
researchers the ability to generate predictions on the individuals who
are at the greatest risk of losing their lives due to an illness. While
the medical world is the most obvious use of survival predictions, the
same methods can be applied to predicting bank failure, the remaining
useful life of machines, machinery maintenance timelines, and insurance
likelihood of payouts. There are various survival methods that can be
examined, including Cox proportional hazards model which will be
examined in this paper.

Cox proportional hazards (CPH) models are statistical regression models
specializing in modeling time-to-event predictions with survival data.
Survival data is data with a value for time and an event
[@Abeysekera2009]. For example, in a study investigating the survival
likelihood of mechanical equipment, the time value would begin when the
equipment begins functioning and would conclude in the event the
equipment stops functioning [@Smith2003]. CPH models can use single or
multiple covariates as a means of creating predictions until failure and
are capable of dealing with survival data that contains censored data as
well [@Seung2023]. Censored data is when the information about an
individual in a study is only known for a certain period of time, such
as the length of the study [@klein2005, 1]. The models also have the
advantage of being semi-parametric which allows more flexibility as
compared to other models [@Ming-Chiang2014].

As mentioned, CPH is used in various fields, primarily the health
industry, but the usage of the model does not come without challenges. A
COVID-19 study done using data from a Pakistani hospital noted that the
model was limited due to the recovery possibility of COVID-19 patients
as CPH assumes as time goes on, the survival probability will approach
zero with no survivors. Though CPH was not the best model for this
study, the results of the model were that individuals who were
asymptomatic and young had a higher chance of surviving the virus
[@asghar2024]. In 2024, a study was done in the US on the relationship
between chest pain occurring and mortality of the person experiencing
chest pain using CPH. A response to that study was written that provided
the limitations of CPH with the biggest concern being the assumption of
constant hazards ratio that CPH relies on for the model. In the heart
study, the effect of Triglyceride-Glucose was assumed to be a constant,
but is actually a value that fluctuates over time along with an
individual's body weight and blood glucose levels. As such, the model
would struggle to predict correctly the effect of Triglyceride-Glucose
given the violation of the constant hazards ratio [@jiang2024].

An additional limitation of CPH comes from the data in the covariates
selected and how they can become biased. Two studies done using UK
health data demonstrated how bias can impact the values for the
covariates when relying on patient submitted information. The first was
a study on the connection between salt intake and the development of
anxiety or depression after 14.5 years [@wang2025] and the second was a
study on the association between postpartum depression and the
development of two or more chronic diseases [@zhang2025]. Both of those
studies relied on patient submitted health data and survey responses
that were supplemented with death records and other accessible health
records thus creating a possible bias in their data which could
negatively influence their model as their covariates may not have
accurately reflected the true data. These articles provide examples of
the care that needs to be taken when working with CPH models.

While health care is the dominant field in which CPH is used, a study in
2021 provides an example of using CPH in insurance fields. An insurance
company in the Czech Republic provides policies for certain illness
events until the event occurs when the insured will receive money and
their contract is complete. To assist the company with predicting if an
individual will have one of the illness events occur, a model using CPH
was generated using gender, age, and region as the covariates
[@zapletal2021]. A study in 2023 focused on the length of productive
life of female Floridian goats to determine the factors that would
impact the longevity of the goats. CPH was used to determine that the
age of first kidding and the specific herd impacts the length of
productive life of the goats [@ziadi2023]. Both of these studies provide
examples of the reaches of CPH models outside the health industry.

CPH has the capability to be applied to many fields, though it poses
some limitations. The constant hazards ratio and determining how to
censor data are two concerns that can lead to limitations in using CPH
for models. In addition, the necessity of a time to event value within
the data source is something that needs to be taken into consideration
when choosing to use CPH. Without that value, using CPH as a survival
model will not be the appropriate method to take with that particular
data. This value is also what makes CPH a prime modeling candidate with
health data as health metrics frequently have a time component to them,
especially when comparing someone over a period of time in a health
study as is done with medications and the development of cancer or other
illnesses. However, while the usage of CPH is clear in the medical
field, this paper will demonstrate using CPH within the field of
mechanics and remaining useful life of a machine.

## Methods

*Notes:*

*How coxph was created and creator what it was made for. it is semi
parametric regression*

*explain mathematically with equation*

*How data needs to be formatted - time + event and covariates*

*how it works*

*assumptions - how to test assumptions*

-   *Detail the models or algorithms used.*

-   *Justify your choices based on the problem and data.*

CPH can be estimated as

$$
h(t|\mathbf{Z}) = h_0(t)\text{exp}(\Sigma_{k=1}^{p} \beta_kZ_k)
$$ {#eq-hazard}

where,

-   $h(t|\mathbf{Z})$ is the hazard rate at time $t$ for an individual
    with risk vector $\mathbf{Z}$
-   $h_0(t)$ is an arbitrary baseline hazard rate
-   $\mathbf{Z}$ is the set of $p$ covariates
-   $\beta$ is the set of $p$ coefficients that measure the impact of
    the covariates

## Analysis and Results

### Data Exploration and Visualization

Though CPH is typically used with health data, we wanted to determine
how CPH can be used in other fields. As such, we will study the
remaining useful life (RUL) of a NASA aircraft engine using data
provided by NASA for the study on propagation modeling [@saxena2008]. In
particular, we will be examining their data from what they have deemed
engine two. From the literature review, we have noted that we will need
to be concerned with the constant hazards ratio within our data and
determine how we will accommodate censored data when creating our model.

Each engine has an unknown amount of wear, manufacturing variation, and
sensor noise all of which impact the survival time. In the training
dataset, each engine is operating normally at the beginning of the time
series, develops a fault, and experiences failure at the end of the time
series. The conditions the engines are subjected to are represented by
three operational setting fields and 21 sensor measurement fields. In
the testing data, the engines have not experienced failure
[@saxena2008].

```{r, echo = FALSE}
#packages
library(tidyverse)
library(gridExtra)
library(survival)
library(survminer)
library(ggpubr)
library(magrittr)
library(ggfortify)
library(knitr)

```

For both test and train datasets, we will need to add a column
indicating status. We will use 0 for still working and 1 for the last
cycle when the engine fails. For the test data, we know that none of the
engines have failed so all values in the test column will be 0 for still
working. For the training data, we know that the data includes all
cycles up to the last cycle when the machine will fail. As such, we will
have 0s in all cycles except the last cycle of the machine.

**Testing Data**

```{r}
testurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/test_FD002.txt'

test <- read.delim(testurl, header = TRUE, sep = '') %>%
  mutate(status = 0)

kable(head(test, n = 5), format = "markdown")
```

**Training Data**

```{r}
trainurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/train_FD002.txt'

train <- read.delim(trainurl, header = TRUE, sep = '') %>%
  group_by(id) %>%
  mutate(status = if_else(row_number() == n(), 1, 0)) %>%
  ungroup() 

kable(head(train, n = 5), format = "markdown")
```

The visual below shows a histogram and a box plot representing
distributions of survival times of the 260 unique engines in the
training data. The survival times have a normal distribution 

The engines have a median survival time of 199 iterations with a
standard deviation of 46.8. The longest surviving engine lasted 378
iterations, with the shortest survival time for all engines being 128.

```{r}
distributions <- train %>% 
  group_by(id) %>%
  summarise(time = max(time))

summarymetrics <- summary(Minimum = min(time),
                          Median = median(time),
                          StandardDeviation = sd(time),
                          Maximum = max(time), 
                          distributions$time) 

kable(tibble(summarymetrics), format = "markdown")

```


```{r, echo=FALSE}
Histogram <- ggplot(data = distributions,
       aes(x = time)) +
  geom_histogram(binwidth = 5,
                 fill = "grey")+
  labs(x = "Survival Time",
       y = "Frequency")+
  theme_bw()

box <- ggplot(data = distributions,
                  aes(y = time))+
  geom_boxplot(fill = "gray",
               color = "black")+
  theme_bw()


grid.arrange(Histogram,box,ncol = 2, top = "Distribution of Engine Longevity in Training Data")

```


The Kaplan-Meier survival curve is shown below.

```{r}
t <- as.matrix(train[, "time"])
s <- as.matrix(train[, "status"])

km_fit <- survfit(Surv(t, s) ~ 1)

autoplot(km_fit) + theme_bw()
```

From the study the data is from, we know that some of the sensors will
not play a role in the RUL. As such, we will run a univariate test of
all covariates to determine which ones will actually impact the RUL. We
will use the p-value provided by the Wald test with a significance level
of $\alpha = 0.05$.

```{r}
covariates <- c("os1", "os2", "os3", "sm1", "sm2", "sm3", "sm4", "sm5", "sm6", "sm7",
                "sm8", "sm9", "sm10", "sm11", "sm12", "sm13", "sm14", "sm15", "sm16",
                "sm17", "sm18", "sm19", "sm20", "sm21")

univ_formulas <- sapply(covariates,
                        function(x) as.formula(paste('Surv(time, status)~', x)))

univ_models <- lapply( univ_formulas, function(x){coxph(x, data = train)})

# Extract data
univ_results <- lapply(univ_models,
                       function(x){
                          x <- summary(x)
                          p.value<-signif(x$wald["pvalue"], digits=2)
                          wald.test<-signif(x$wald["test"], digits=2)
                          beta<-signif(x$coef[1], digits=2);#coefficient beta
                          HR <-signif(x$coef[2], digits=2);#exp(beta)
                          HR.confint.lower <- signif(x$conf.int[,"lower .95"], 2)
                          HR.confint.upper <- signif(x$conf.int[,"upper .95"],2)
                          HR <- paste0(HR, " (",
                                       HR.confint.lower, "-", HR.confint.upper, ")")
                          res<-c(beta, HR, wald.test, p.value)
                          names(res)<-c("beta", "HR (95% CI for HR)", "wald.test",
                                        "p.value")
                          return(res)
                         })
kable(as.data.frame(univ_results))
```

Assumptions

Proportional Hazards Assumption

The proportional hazards assumption states the ratio of hazard rates for any two individuals is constant over time regardless of the point in time of the measurement. 

The proportional hazards assumption has been proven to be critical for evaluating prior to using Cox Proportional Hazards to model survival data.



-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

### Modeling

```{r}
cox <- coxph(Surv(time, status) ~ os1 + os3 + sm1 + sm2 + sm5,
             data = train)

summary(cox)
```
```{r}
cox.zph(cox)

plot(cox.zph(cox))
```


A study was conducted to determine how...Modeling and Results

-   Explain your data preprocessing and cleaning steps.
transformation applied to data to add event

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

### Results

## Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
