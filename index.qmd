---
title: "Predicting Remaining Useful Life of NASA Aircraft Engines"
subtitle: "Using Cox Proportional Hazards Model"
author: "Jayme Reed & Brad Paton (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    theme: spacelab
    toc: true
    toc-depth: 3
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Slides](slides.html){target="_blank"} \|
[Literature](articleSummaries.html)

```{r, echo = FALSE, warning=FALSE, include=FALSE}
#Load packages
library(tidyverse)
library(gridExtra)
library(grid)
library(survival)
library(survminer)
library(ggpubr)
library(magrittr)
library(ggfortify)
library(knitr)
library(sjPlot)

```

## Introduction

As the COVID-19 pandemic demonstrated, the ability to predict the
survival of a patient based on their symptoms and medical history is a
major benefit as society deals with health crises such as pandemics.
Those predictions would assist medical practitioners in triage and allow
researchers the ability to generate predictions on the individuals who
are at the greatest risk of losing their lives due to an illness. While
the medical world is the most obvious use of survival predictions, the
same methods can be applied to predicting bank failure, the remaining
useful life of machines, machinery maintenance timelines, and insurance
likelihood of payouts. There are various survival methods that can be
examined, including Cox proportional hazards model which will be
examined in this paper.

Cox proportional hazards (CPH) models are statistical regression models
specializing in modeling time-to-event predictions with survival data.
Survival data is data with a value for time and an event
[@Abeysekera2009]. For example, in a study investigating the survival
likelihood of mechanical equipment, the time value would begin when the
equipment begins functioning and would conclude in the event the
equipment stops functioning [@Smith2003]. CPH models can use single or
multiple covariates as a means of creating predictions until failure and
are capable of dealing with survival data that contains censored data as
well [@Seung2023]. Censored data is when the information about an
individual in a study is only known for a certain period of time, such
as the length of the study [@klein2005, 1]. The models also have the
advantage of being semi-parametric which allows more flexibility as
compared to other models [@Ming-Chiang2014].

As mentioned, CPH is used in various fields, primarily the health
industry, but the usage of the model does not come without challenges. A
COVID-19 study done using data from a Pakistani hospital noted that the
model was limited due to the recovery possibility of COVID-19 patients
as CPH assumes as time goes on, the survival probability will approach
zero with no survivors. Though CPH was not the best model for this
study, the results of the model were that individuals who were
asymptomatic and young had a higher chance of surviving the virus
[@asghar2024]. In 2024, a study was done in the US on the relationship
between chest pain occurring and mortality of the person experiencing
chest pain using CPH. A response to that study was written that provided
the limitations of CPH with the biggest concern being the assumption of
constant hazards ratio that CPH relies on for the model. In the heart
study, the effect of Triglyceride-Glucose was assumed to be a constant,
but is actually a value that fluctuates over time along with an
individual's body weight and blood glucose levels. As such, the model
would struggle to predict correctly the effect of Triglyceride-Glucose
given the violation of the constant hazards ratio [@jiang2024].

An additional limitation of CPH comes from the data in the covariates
selected and how they can become biased. Two studies done using UK
health data demonstrated how bias can impact the values for the
covariates when relying on patient submitted information. The first was
a study on the connection between salt intake and the development of
anxiety or depression after 14.5 years [@wang2025] and the second was a
study on the association between postpartum depression and the
development of two or more chronic diseases [@zhang2025]. Both of those
studies relied on patient submitted health data and survey responses
that were supplemented with death records and other accessible health
records thus creating a possible bias in their data which could
negatively influence their model as their covariates may not have
accurately reflected the true data. These articles provide examples of
the care that needs to be taken when working with CPH models.

While health care is the dominant field in which CPH is used, a study in
2021 provides an example of using CPH in insurance fields. An insurance
company in the Czech Republic provides policies for certain illness
events until the event occurs when the insured will receive money and
their contract is complete. To assist the company with predicting if an
individual will have one of the illness events occur, a model using CPH
was generated using gender, age, and region as the covariates
[@zapletal2021]. A study in 2023 focused on the length of productive
life of female Floridian goats to determine the factors that would
impact the longevity of the goats. CPH was used to determine that the
age of first kidding and the specific herd impacts the length of
productive life of the goats [@ziadi2023]. Both of these studies provide
examples of the reaches of CPH models outside the health industry.

CPH has the capability to be applied to many fields, though it poses
some limitations. The constant hazards ratio and determining how to
censor data are two concerns that can lead to limitations in using CPH
for models. In addition, the necessity of a time to event value within
the data source is something that needs to be taken into consideration
when choosing to use CPH. Without that value, using CPH as a survival
model will not be the appropriate method to take with that particular
data. This value is also what makes CPH a prime modeling candidate with
health data as health metrics frequently have a time component to them,
especially when comparing someone over a period of time in a health
study as is done with medications and the development of cancer or other
illnesses. However, while the usage of CPH is clear in the medical
field, this paper will demonstrate using CPH within the field of
mechanics and remaining useful life of a machine.

## Methods

### Mathematical Formulas

There are two functions that are the backbone for CPH: the survival
function and the hazard function. The survival function when $X$ is a
continuous random variable is

$$
S(x) = 1 - F(x) = 1 - Pr(X > x) = \int_x^\infty f(x) dx
$$ {#eq-survival}

where $S(x)$ is the probability that an individual has survived past
time $x$ [@klein2005]. undefined

The hazard function, which is also known as the hazard rate function,
can be defined as

$$
 h(x) = \lim_{\Delta x \rightarrow 0} \frac{P[x\leq X < x + \Delta x | X \geq x]}{\Delta x}
$$ {#eq-hazardrate}

The function is used to describe the changes in [@klein2005].

Since CPH is a proportional hazard model, the hazard function is adapted
to deal with the relationship between time to event and the explanatory
variables [@klein2005]. It can be defined as

$$
h(t|\mathbf{Z} ) = h_0(t)\text{exp}(\sum_{k=1}^p \beta_kZ_k)
$$ {#eq-coxhazard}

where,

-   $h(t|\mathbf{Z})$ is the hazard rate at time $t$ for an subject with
    risk vector $\mathbf{Z}$
-   $h_0(t)$ is a baseline hazard rate when all covariates are $0$
-   $\text{exp}(\sum_{k=1}^p \beta_k Z_k)$ is a semi-parametric model
-   $\beta_k$ is a parameter vector
-   $Z_k$ is the risk vector [@klein2005]

CPH is considered a proportional hazards model due to the hazard ratio
between two individuals being a constant value. The ratio of the hazard
function for an individual with $\mathbf{Z}$ covariates where
$Z_k = z+1$ and for an individual with $\mathbf{Z}^*$ covariates where
$Z_k = z$ with all other predictors are fixed [@nahhas2025] is defined
as

$$
\frac{h(t|\mathbf{Z})}{h(t|\mathbf{Z}^*)} = \frac{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z_k]}{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z^*_k]} = \text{exp}[\sum_{k=1}^p \beta_k(Z_k - Z_k^*)]
$$ {#eq-hazardratio}[@klein2005]. The result of the hazard ratio (HR) is
a constant that implies an association between a continuous predictor
and the outcome. The interpretation of the HR is

-   if HR $> 1$ implies a positive association such that
    $100\% \times (HR - 1)$ is the \\% of greater risk for $Z = z+1$
    when compared to $Z = z$.
-   if HR $< 1$ implies a negatie association such that
    $100\% \times (HR -1)$ is the \\% of decreased risk for $Z = z+1$
    when compared to $Z= z$.
-   if HR $=1$ implies no association. [@nahhas2025]

An additional useful equations is the cumulative hazard function. The
cumulative hazard function can be defined as

$$
 H(x) = \int_0^x h(u) du 
$$ {#eq-cumulativehr}

where $h(u)$ is the hazard rate function [@klein2005]. This function
provides a better understanding of the survival function for graphing
purposes.[@Amini2015]

### Data Structure

In order to use CPH to model time to event survival data, the data must
contain a value for time, a binary field indicating the event being
modeled, an id field, and one or multiple covariate fields. The time
value is typically formatted as a time series for each subject in the
dataset. Subjects will have a time value from the beginning of the
observation period, to an arbitrary time that may or may not be the time
the event being modeled for occurs. Data is considered censored when the
subject is not given the opportunity to experience the event in the
observation period and is handled differently by the model. The
covariate fields in the dataset can be categorical or numerical
[@nahhas2025].

### Creating Cox Proportional Hazards Model

After verifying the survival data is formatted properly, the CPH model
can be created in R. Important steps to consider are choosing covariates
and verifying the model meet the model's assumptions after the model is
created.

#### Choosing covariates

From the study the data is from, we know that some of the sensors will
not play a role in the RUL. As such, we will run a univariate test of
all covariates to determine which ones will actually impact the RUL. We
will use the p-value provided by the Wald test with a significance level
of $\alpha = 0.05$.

#### Generating Model

During the analysis, multiple models will be created with a different
combination of covariates. Covariates will be considered in the models that pass the covariate test. After creating the models, the assumptions described below will be tested. Out of the multiple models created, models will also not be considered where the assumptions are not true.

The model used through the rest of the analysis to make predictions will be the model with the best evaluation where the assumptions ar true.

### Assumptions

When creating a CPH model, to ensure an accurate model is created the
following assumptions must be met. If they are not met, the data must
either be transformed, stratified, or other covariates may need to be
selected for the model. The assumptions associated with the CPH model
are defined below.

#### Proportional Hazards Assumption

The proportional hazards assumption has been proven to be critical to
evaluate prior to using CPH when modeling survival data. The
proportional hazards assumption states that the ratio of hazard rates
for any two subjects must be constant over time regardless of the point
in time of the measurement. This means the effect of the covariates must
be constant over time. [@Bustan2018]

This assumption can be tested with a hypothesis test using the hypothesis:

$$
\begin{align*}
H_0&: \text{the predictor's coefficient does vary with time} \\
H_1&: \text{the predictor's coefficient does not vary with time}
\end{align*}
$$

The `cox.zph()` function calculates the scaled Schoenfeld partial residuals and
returns the $\chi^2$ value, the degrees of freedom, and p-values for
each individual covariate along with a global value. Using an
$\alpha = 0.05$ and the global p-value, the determination of whether to
reject or fail to reject $H_0$ can be made. In addition to the
hypothesis test, these Shoenfeld residuals can be plotted against time
for each covariate to visualize the assumption. When plotting the
residuals against time, if the assumption is not broken it would be
expected that the points show roughly a straight horizontal line to
indicate constant hazard over time [@nahhas2025].

Individual plots for each covariate are generated which provide a visual
interpretation of the p-values generated from `cox.zph()`. If there is
no clear slope in the residuals on the plot, it signifies further
confirmation the proportional hazards assumption is met.

Below is an example plot demonstrating Shoenfeld residuals plotted
against time to test the proportional hazards assumption. While there is
some curvature in the line, the residuals are roughly horizontal
indicating proportional hazard over time for this covariate. In a model
with multiple covariates, each one would need to be visualized to ensure
it does not break this assumption and can be used in the model.

```{r, echo=FALSE}
example_surv_object <- Surv(time = lung$time, event = lung$status)

example_coxmodel <- coxph(example_surv_object ~ meal.cal + age, data = lung)

example_phtest <- cox.zph(example_coxmodel)

plot(example_phtest[1],
     ylab = "Covariate Schoenfeld Residual",
     xlab = "Time")
```

#### Linearity Assumption

The linearity assumption states that the relationship between covariates
and the log of the hazard rate must be linear. This assumption can be
checked by plotting Martingale residuals against the range of values
present in each covariate.

Martingale residuals are a type of residuals used in survival analysis
that show the discrepancy between the observed and expected number of
events. $MartingaleResiduals = ObservedEvents - ExpectedEvents$

If the resulting residuals are linear and appear to have a slope of
zero, this assumption is not violated.[@Amini2015]

Below is an example plot showing Martingale residuals plotted against
the range of values in the covariate being tested. From the plot, it is
clear there is no clear slope in the residuals indicating the linearity
assumption is not broken. For a model with multiple covariates, multiple
plots will need to be made.

```{r,echo=FALSE}
example_martingale <- resid(example_coxmodel, type = "martingale")

plot(example_martingale, 
     main = "Martingale Residuals: Example Covariate",
     ylab = "Martingale Residuals for Example Covariate",
     xlab = "Value Range for Example Covariate")
abline(h = 0, col = "red")
```

#### Independent Censoring Assumption

This assumption describes how if an event is censored it should not be
considered when the model is being created. Censored data is difficult
to accommodate when Cox proportional hazards models are used in other
industries, such as the medical field, because observation times for the
subjects involved in studies may have decades before an event is
observed and the event may not have the opportunity to occur during the
study period. In this scenario, it would not be appropriate to consider
this subject when modeling survival.[@Amini2015]

#### Independence Assumption

Survival times of observed subjects should be independent of each other.
In an example where survival of plane engines were being evaluated, if
each plane has two engines and the failure of one engine caused the
accelerated failure of another due to increased workload, it would
produce biased conclusions and violate the independence assumption.[@Amini2015]

### Model Evaluation

**Concordance Index**

To evaluate the model, the Cox regression concordance index can be used.
Two observed pairs are said to be concordant if an event that is
expected to occur before another does occur first. For example, if two
engines are selected from the data and the model predicts one of them to
be at a higher risk of failure than the other and the one with the
higher risk fails first, then the pairs are concordant. If the
alternative happens where the lower risk engine experiences failure
first, then the pairs are discordant.

The concordance index is calculated as follows:

$C = \frac{ConcordantPairs}{ConcordantPairs + DiscordantPairs}$

The concordance index will produce a value between 0 and 1 with 1
meaning all pairs are correctly ordered and 0 being the alternative with
no pairs correctly ordered. The higher the concordance index for the
created model, the more accurately it can model survival for the
data.[@Therneau2017]

### Model Visualization and Prediction

There are multiple different methods to visualize data when creating a
Cox proportional hazards model. Survival curves are a popular way to
visualize survival probabilities over time, but there are other
visualizations that are helpful when interpreting the results of the
model.

Cox proportional hazards models can produce an assortment of useful
metrics to interpret the model as described by the equations above. The model created can be used to
estimate risk of the event occurring, rate of occurrence, survival
probability, and time to event.

#### Forest Plot

Forest plots can be used to visualize the effects of each covariate in
the model on the hazard ratio. The resulting plot contains each
covariate on the y axis, with the estimated effect on the hazard ratio
on the the x axis. The plot contains whiskers demonstrating a 95%
confidence interval for the effect. A positive effect indicates a
positive correlation with the hazard with a higher number signifying a
more severe effect on the hazard ratio.

An example forest plot is shown below
plotting the hazard ratio for each covariate in the model. The point
represents the calculated hazard ratio and the whiskers show the 95%
confidence interval.

```{r, echo=FALSE,warning=FALSE}
plot_model(example_coxmodel,
           dot.size = 1,
           line.size = 1,
           colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")
```

#### Kaplan-Meier Survival Curve

After generating the CPH model, a Kaplan-Meier survival curve can be
generated to view survival probabilities against time. These plots are
important when modeling survival data because they clearly demonstrate
the time where the event being modeled for is expected to occur.

Below is an example survival curve showing survival probabilities over
time. The line represents the median survival probability with the red
area around it showing the 95% confidence interval for the values. The
curve can be interpreted as showing the probability of event would be
expected to happen around a time of 300 where the survival probability
is below 50%.[@Kuitunen2021]

```{r, echo=FALSE}
example_curve <- survfit(example_coxmodel)

ggsurvplot(example_curve,
           data = lung,
           title = "Example Survival Curve",
           xlab = "Time",
           ylab = "Survival Probability",
           legend = "none")

```


#### Predicting Time Until Event

Time until event can be calculated by modeling survival probability for
future time values. When survival probability drops below 50%, it will
be assumed the event occurred. Predictions for time until event will be
made on the testing data for each individual's maximum time value. A
column will be added to the table showing the expected time until event.



## Analysis and Results

### Data Structure, Exploration, and Visualization

Though CPH is typically used with health data, we wanted to determine
how CPH can be used in other fields. As such, we will study the
remaining useful life (RUL) of a NASA aircraft engine using data
provided by NASA for the study on propagation modeling [@saxena2008]. In
particular, we will be examining their data from what they have deemed
engine two. From the literature review, we have noted that we will need
to be concerned with the constant hazards ratio within our data and
determine how we will accommodate censored data when creating our model.

#### Data Structure

Each engine has an unknown amount of wear, manufacturing variation, and
sensor noise all of which impact the survival time. In the training
dataset, each engine is operating normally at the beginning of the time
series, develops a fault, and experiences failure at the end of the time
series. The conditions the engines are subjected to are represented by
three operational setting fields and 21 sensor measurement fields. In
the testing data, the engines have not experienced failure
[@saxena2008].

For both test and train datasets, we will need to add a column
indicating status. We will use 0 for still working and 1 for the last
cycle when the engine fails. For the test data, we know that none of the
engines have failed so all values in the test column will be 0 for still
working. For the training data, we know that the data includes all
cycles up to the last cycle when the machine will fail. As such, we will
have 0s in all cycles except the last cycle of the machine.

Below are tables showing the structure of the training and testing data after the transformations describd above.

**Testing Data**

```{r}
testurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/test_FD002.txt'

test <- read.delim(testurl, header = TRUE, sep = '') %>%
  mutate(status = 0)

kable(head(test, n = 5), format = "markdown")
```

**Training Data**

```{r}
trainurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/train_FD002.txt'

train <- read.delim(trainurl, header = TRUE, sep = '') %>%
  group_by(id) %>%
  mutate(status = if_else(row_number() == n(), 1, 0)) %>%
  ungroup() 

kable(head(train, n = 5), format = "markdown")
```

#### Data Visualization

The visuals below describe the distribution of the 260 engines in the
training data. The histogram shows the survival times are normally
distributed with a median value of 199 iterations and the box plot shows
there are few outliers out of the 260 engines. The engines have a median
survival time of 199 iterations with a standard deviation of 46.8. The
longest surviving engine lasted 378 iterations, with the shortest
survival time for all engines being 128.

```{r}
distributions <- train %>% 
  group_by(id) %>%
  summarise(time = max(time))

summarymetrics <- summary(Minimum = min(time),
                          Median = median(time),
                          StandardDeviation = sd(time),
                          Maximum = max(time), 
                          distributions$time) 

kable(tibble(summarymetrics), format = "markdown")

```

```{r, echo=FALSE}
Histogram <- ggplot(data = distributions,
       aes(x = time)) +
  geom_histogram(binwidth = 5,
                 fill = "grey")+
  labs(x = "Survival Time (Iterations)",
       y = "Frequency")+
  theme_bw()

box <- ggplot(data = distributions,
                  aes(y = time))+
  geom_boxplot(fill = "gray",
               color = "black")+
  ylab("Time (Iterations)")+
  theme_bw()


grid.arrange(Histogram,box,ncol = 2, top = "Distribution of Engine Longevity in Training Data")

```

The Kaplan-Meier survival curve is shown below.

```{r}
t <- as.matrix(train[, "time"])
s <- as.matrix(train[, "status"])

km_fit <- survfit(Surv(t, s) ~ 1)

autoplot(km_fit) + theme_bw()
```

### Creating Cox Proportional Hazards Model

#### Choosing Covariates

Below is a univariate test to determine which covariates to use in the
model. 

```{r}
covariates <- c("os1", "os2", "os3", "sm1", "sm2", "sm3", "sm4", "sm5", "sm6", "sm7",
                "sm8", "sm9", "sm10", "sm11", "sm12", "sm13", "sm14", "sm15", "sm16",
                "sm17", "sm18", "sm19", "sm20", "sm21")

univ_formulas <- sapply(covariates,
                        function(x) as.formula(paste('Surv(time, status)~', x)))

univ_models <- lapply( univ_formulas, function(x){coxph(x, data = train)})

# Extract data
univ_results <- lapply(univ_models,
                       function(x){
                          x <- summary(x)
                          p.value<-signif(x$wald["pvalue"], digits=2)
                          wald.test<-signif(x$wald["test"], digits=2)
                          beta<-signif(x$coef[1], digits=2);#coefficient beta
                          HR <-signif(x$coef[2], digits=2);#exp(beta)
                          HR.confint.lower <- signif(x$conf.int[,"lower .95"], 2)
                          HR.confint.upper <- signif(x$conf.int[,"upper .95"],2)
                          HR <- paste0(HR, " (",
                                       HR.confint.lower, "-", HR.confint.upper, ")")
                          res<-c(beta, HR, wald.test, p.value)
                          names(res)<-c("beta", "HR (95% CI for HR)", "wald.test",
                                        "p.value")
                          return(res)
                         })
kable(as.data.frame(univ_results))
```

#### Creating Model

To generate the CPH model, a
survival object must first be created using the R package `survival`.
The survival object is created by running `Surv(time, event)` where
`time` is the time field and `event` is the event field.

To create the CPH model, the survival object is then applied to the R
function `coxph(survival object ~ x, data)` where `x` represents one or
multiple covariate(s) and `data` is the survival data that is being
modeled.[@R-base].

```{r}
cox1 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm1 + sm2 + sm5 + sm6 + sm7 + sm11 + sm12 + sm13 + sm14 + sm19 + sm20 + sm21)

cox2 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm1 + sm2 + sm5)

cox3 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm1 + sm5 + sm6 + sm7 + sm13 + sm14 + sm19 + sm21)

cox4 <- coxph(data = train, 
             Surv(time, status) ~ sm5 + sm6 + sm7 + sm11 + sm12 + sm13 + sm14 + sm19 + sm20 + sm21)

cox5 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm1 + sm2 + sm5  + sm7 + sm11 + sm12 + sm13 + sm19 + sm20 )

cox6 <- coxph(data = train, 
             Surv(time, status) ~ os1  + sm1 + sm2 + sm5  + sm7 + sm11 + sm12 + sm13 + sm19  + sm21)

cox7 <- coxph(data = train, 
             Surv(time, status) ~ os1  + sm13 + sm14 + sm19 + sm20)

cox8 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm21)

cox9 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm2 + sm5 + sm6 + sm12 + sm13  + sm19 + sm20 + sm21)

cox10 <- coxph(data = train, 
             Surv(time, status) ~  os3 + sm1 + sm2 + sm5 + sm6  + sm11 + sm12 + sm13  + sm19 + sm20 + sm21)


```

The resulting models and their corresponding concordance index values are below. 

```{r}
concordance_results <- data.frame(row.names = c(
  "Model 1",
  "Model 2",
  "Model 3",
  "Model 4",
  "Model 5",
  "Model 6",
  "Model 7",
  "Model 8",
  "Model 9",
  "Model 10"),
  Concordance = c(
  cox1$concordance[6],
  cox2$concordance[6],
  cox3$concordance[6],
  cox4$concordance[6],
  cox5$concordance[6],
  cox6$concordance[6],
  cox7$concordance[6],
  cox8$concordance[6],
  cox9$concordance[6],
  cox10$concordance[6]))


kable(concordance_results)

```

The analysis will proceed using model 1 because of the high concordance index. The full summary of model 1 is below.

```{r}
summary(cox1)

```


### Checking Assumptions

Despite the high concordance value for model 1, the assumptions will need to be evaluated before using the model to make predictions. If any of the assumptions for the model are not true, the model will need to be modified

#### Checking Proportional Hazards Assumption
The `cox.zph` function can be used to check the proportional hazards assumption. As mentioned above, the function calculates p values for each covariate. If the p values are < .05, the null hypothesis is rejected indicating the proportional hazards assumption is true. If the proportional hazards assumption is not true for any covariate, the model will be recreated without those covariates.

```{r}
cox.zph(cox1)
```
The output above shows the p values for the hypothesis test. 

In addition to the hypothesis test, the Shoenfeld residuals calculated by the `cox.zph()` function are plotted against time below.

```{r}
# Function to put ph_plots on one visual
create_ph_plots <- function(coxmodel){
  # Function takes argument that is a cox model from coxph()
  
  phresults <- cox.zph(coxmodel)

  # Define dimensions of visual
  par(mfrow = c(3,5),
      mar = c(2,2,4,1))


  # Loop through each covariate creating a plot and adding it to the phplot list
  for (i in 1:(length(phresults$table[,1])-1)){
    phplots <- list()
    phplots[i] <- plot(phresults[i], # Create plot for each iteration
                       main = rownames(phresults$table)[i]) # Title of each plot is the rowname from coxmodel$table
  
  }
  mtext("Schoenfeld Residuals vs. Time for Covariates", side = 3, line = -1.5, outer = TRUE, cex = 1) # Title for Visual
  par(mfrow = c(1,1)) # Reset plotting area
}

create_ph_plots(cox1)
```

The proportional hazards test shows several covariates do not meet the proportional hazards assumption. 

The model is recreated below with another proportional hazards test.

```{r}

cox1.1 <- coxph(data = train, 
             Surv(time, status) ~ os1 + os3 + sm1 + sm2 + sm5 + sm6 + sm7 + sm11 + sm12 + sm13 + sm14 + sm19 + sm20 + sm21)
cox.zph(cox1.1)

```



The hypothesis test shows the covariates sm1, sm2, sm6, sm7, sm11, sm12, sm20, and sm21 do not meet the proportional hazards assumption. The model is created again below with a second hypothesis test showing all of the covariates pass the hypothesis test.


#### Checking Linearity Assumption

Residuals can first be found by using the `resid(type = "martingale")`
function and passing martingale in the type argument creating a vector
of residuals that can be plotted against the range of values for each
covariate.
Example for one predictor

```{r}
martingale <- resid(cox1.1, type = "martingale")

plot(train$os1, martingale, main = "Martingale Residuals: os1")
abline(h = 0, col = "red")


```

#### Checking Independent Censoring

In the dataset being used for this model, the training data does not
contain censored data. The documentation available at the dataset's
source clarifies all engines in the training data have experienced the
desired event of failure.

### Model Evaluation

### Model Visualization

Forest Plot

A forest plot will be created using the `plot_model()` function from the
sjPlot package. The CPH model can be passed as the sole argument to
visualize the hazard ratios.

```{r}
plot_model(cox1.1,dot.size = 4,line.size = 2,colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")
```

survival curve

 The
survival curve will be plotted by using the survival package's
`survfit()` function. The object created will be plotted using `plot()`
```{r}
survfit <- survfit(cox1.1)

ggsurvplot(survfit, data = test)
```

### Model Applications and Predictions

Create df with max time for each individual to use in predictions

```{r}
#predictiondata <- test %>%
  #group_by(id) %>%
  #slice_max(time) %>%
  #select(id, time, os1, os3, sm1, sm2, sm5, status)

#coef <- data.frame(Variable = c("Z1", "Z2", "Z3", "Z4", "Z5"),
           #CoefficientValue = cox1.1$coefficients)
#kable(coef)
```

Hazard Rate Calculation:
$h(t|Z) = h_0(t) * e^{B_1Z_1 + B_2Z_2 + B_3Z_3+B_4Z_4+B_5Z_5}$

```{r}
test$hazardrates <- predict(cox1.1,
        newdata = test,
        type = "risk")

```

$H(t) = \int_0^t h(t) dt$ where, $H(t)$ is the cumulative hazard from
time 0 to time $(t)$ $h(t)$ is the hazard rate at time $t$

```{r}
test <- test %>%
  arrange(id, time) %>%
  group_by(id) %>%
  mutate(cumulative_hazard = cumsum(hazardrates))
```

Predicting survival probability

```{r}
test$survprob <- predict(cox1.1, type = "survival", newdata = test)

```

Probability Calculation: $S(t) = e^{-H(t)}$ $H(t)$ is the cumulative
hazard up to time $t$

Tim until event can be modeled in R by passing the `type = "lp"`
argument in the `stats::predict()` function to get a value for linear
predictor.

```{r}

```


A study was conducted to determine how...Modeling and Results

-   Explain your data preprocessing and cleaning steps. transformation
    applied to data to add event

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

### Results

## Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
