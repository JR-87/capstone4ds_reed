---
title: "Predicting Remaining Useful Life of NASA Aircraft Engines"
subtitle: "Using Cox Proportional Hazards Model"
author: "Jayme Reed & Brad Paton (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    theme: spacelab
    toc: true
    toc-depth: 3
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

[Slides](slides.html){target="_blank"} \|
[Literature](articleSummaries.html)

```{r, echo = FALSE, warning=FALSE, include=FALSE}
#Load packages
library(tidyverse)
library(gridExtra)
library(grid)
library(survival)
library(survminer)
library(ggpubr)
library(magrittr)
library(ggfortify)
library(knitr)
library(sjPlot)
library(broom)

```

## Introduction

As the COVID-19 pandemic demonstrated, the ability to predict the
survival of a patient based on their symptoms and medical history is a
major benefit as society deals with health crises such as pandemics.
Those predictions would assist medical practitioners in triage and allow
researchers the ability to generate predictions on the individuals who
are at the greatest risk of losing their lives due to an illness. While
the medical world is the most obvious use of survival predictions, the
same methods can be applied to predicting bank failure, the remaining
useful life of machines, machinery maintenance timelines, and insurance
likelihood of payouts. There are various survival methods that can be
examined, including Cox proportional hazards model which will be
examined in this paper.

Cox proportional hazards (CPH) models are statistical regression models
specializing in modeling time-to-event predictions with survival data.
Survival data is data with a value for time and an event
[@Abeysekera2009]. For example, in a study investigating the survival
likelihood of mechanical equipment, the time value would begin when the
equipment begins functioning and would conclude in the event the
equipment stops functioning [@Smith2003]. CPH models can use single or
multiple covariates as a means of creating predictions until failure and
are capable of dealing with survival data that contains censored data as
well [@Seung2023]. Censored data is when the information about an
individual in a study is only known for a certain period of time, such
as the length of the study [@klein2005]. The models also have the
advantage of being semi-parametric which allows more flexibility as
compared to other models [@Ming-Chiang2014].

As mentioned, CPH is used in various fields, primarily the health
industry, but the usage of the model does not come without challenges. A
COVID-19 study done using data from a Pakistani hospital noted that the
model was limited due to the recovery possibility of COVID-19 patients
as CPH assumes as time goes on, the survival probability will approach
zero with no survivors. Though CPH was not the best model for this
study, the results of the model were that individuals who were
asymptomatic and young had a higher chance of surviving the virus
[@asghar2024]. In 2024, a study was done in the US on the relationship
between chest pain occurring and mortality of the person experiencing
chest pain using CPH. A response to that study was written that provided
the limitations of CPH with the biggest concern being the assumption of
constant hazards ratio that CPH relies on for the model. In the heart
study, the effect of Triglyceride-Glucose was assumed to be a constant,
but is actually a value that fluctuates over time along with an
individual's body weight and blood glucose levels. As such, the model
would struggle to predict correctly the effect of Triglyceride-Glucose
given the violation of the constant hazards ratio [@jiang2024].

An additional limitation of CPH comes from the data in the covariates
selected and how they can become biased. Two studies done using UK
health data demonstrated how bias can impact the values for the
covariates when relying on patient submitted information. The first was
a study on the connection between salt intake and the development of
anxiety or depression after 14.5 years [@wang2025] and the second was a
study on the association between postpartum depression and the
development of two or more chronic diseases [@zhang2025]. Both of those
studies relied on patient submitted health data and survey responses
that were supplemented with death records and other accessible health
records thus creating a possible bias in their data which could
negatively influence their model as their covariates may not have
accurately reflected the true data. These articles provide examples of
the care that needs to be taken when working with CPH models.

While health care is the dominant field in which CPH is used, a study in
2021 provides an example of using CPH in insurance fields. An insurance
company in the Czech Republic provides policies for certain illness
events until the event occurs when the insured will receive money and
their contract is complete. To assist the company with predicting if an
individual will have one of the illness events occur, a model using CPH
was generated using gender, age, and region as the covariates
[@zapletal2021]. A study in 2023 focused on the length of productive
life of female Floridian goats to determine the factors that would
impact the longevity of the goats. CPH was used to determine that the
age of first kidding and the specific herd impacts the length of
productive life of the goats [@ziadi2023]. Both of these studies provide
examples of the reaches of CPH models outside the health industry.

CPH has the capability to be applied to many fields, though it poses
some limitations. The constant hazards ratio and determining how to
censor data are two concerns that can lead to limitations in using CPH
for models. In addition, the necessity of a time to event value within
the data source is something that needs to be taken into consideration
when choosing to use CPH. Without that value, using CPH as a survival
model will not be the appropriate method to take with that particular
data. This value is also what makes CPH a prime modeling candidate with
health data as health metrics frequently have a time component to them,
especially when comparing someone over a period of time in a health
study as is done with medications and the development of cancer or other
illnesses. However, while the usage of CPH is clear in the medical
field, this paper will demonstrate using CPH within the field of
mechanics and remaining useful life of a machine.

## Methods

### Mathematical Formulas

There are two functions that are the backbone for CPH: the survival
function and the hazard function. The survival function when $X$ is a
continuous random variable is

$$
S(x) = 1 - F(x) = 1 - Pr(X > x) = \int_x^\infty f(x) dx
$$ {#eq-survival}

where $S(x)$ is the probability that an individual has survived past
time $x$ [@klein2005].

The hazard function, which is also known as the hazard rate function,
can be defined as

$$
 h(x) = \lim_{\Delta x \rightarrow 0} \frac{P[x\leq X < x + \Delta x | X \geq x]}{\Delta x}
$$ {#eq-hazardrate}

The function is used to describe how the chance of experiencing the
event changes with time and only has the requirement of being
non-negative [@klein2005].

CPH then uses both functions to develop it's own model, specifically by
adapting the hazard function. Since CPH is a proportional hazard model,
the hazard function is adapted to deal with the relationship between
time to event and the explanatory variables [@klein2005]. It can be
defined as

$$
h(t|\mathbf{Z} ) = h_0(t)\text{exp}(\sum_{k=1}^p \beta_kZ_k)
$$ {#eq-coxhazard}

where,

-   $h(t|\mathbf{Z})$ is the hazard rate at time $t$ for an subject with
    risk vector $\mathbf{Z}$
-   $h_0(t)$ is a baseline hazard rate when all covariates are $0$
-   $\text{exp}(\sum_{k=1}^p \beta_k Z_k)$ is a semi-parametric model
-   $\beta_k$ is a parameter vector
-   $Z_k$ is the risk vector [@klein2005]

CPH is considered a proportional hazards model due to the hazard ratio
between two individuals being a constant value. The ratio of the hazard
function for an individual with $\mathbf{Z}$ covariates where
$Z_k = z+1$ and for an individual with $\mathbf{Z}^*$ covariates where
$Z_k = z$ with all other predictors are fixed [@nahhas2025] is defined
as

$$
\frac{h(t|\mathbf{Z})}{h(t|\mathbf{Z}^*)} = \frac{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z_k]}{h_0(t)\text{exp}[\sum_{k=1}^p \beta_k Z^*_k]} = \text{exp}[\sum_{k=1}^p \beta_k(Z_k - Z_k^*)]
$$ {#eq-hazardratio}[@klein2005]. The result of the hazard ratio (HR) is
a constant that implies an association between a continuous predictor
and the outcome. The interpretation of the HR is

-   if HR $> 1$ implies a positive association such that
    $100\% \times (HR - 1)$ is the \\% of greater risk for $Z = z+1$
    when compared to $Z = z$.
-   if HR $< 1$ implies a negative association such that
    $100\% \times (HR -1)$ is the \\% of decreased risk for $Z = z+1$
    when compared to $Z= z$.
-   if HR $=1$ implies no association. [@nahhas2025]

An additional useful equation is the cumulative hazard function. The
cumulative hazard function can be defined as

$$
\begin{align*}
 H(x) = \int_0^x h(u) du 
\end{align*}
$$ {#eq-cumulativehr}

where $h(u)$ is the hazard rate function [@klein2005]. This function
provides a better understanding of the survival function for graphing
purposes.

### Covariate Selection

Depending on the study, there will be covariates that do not impact the
probability of survival. Statistical methods such as the Wald Test can
be used to determine which ones to use in the final CPH model.
Generating a univariate CPH model for each covariate and using the Wald
test with a significance level of $\alpha = 0.05$ will allow for
determination of if a covariate is significant. Any covariates that are
determined to be not significant to the survival probability can be
removed from the final CPH model.

### Assumptions

```{r, echo = FALSE}
#generation of the model for sample plots
example_surv_object <- Surv(time = lung$time, event = lung$status)

example_coxmodel <- coxph(example_surv_object ~ meal.cal, data = lung)
```

There are four assumptions that a CPH model must meet in order to be an
accurate model. For any violation of those assumptions, the data will
need to be either transformed, stratified, or other covariates may need
to be selected for the model. The four assumptions are the independence
assumption, non-informative censoring, linearity assumption, and
proportional hazards assumption.

**Independence Assumption**

CPH assumes that the survival times of observed subjects are independent
of each other. This is similar to most regression models, though CPH
does not assume that the residuals of the model be normally distributed
or have constant variance [@nahhas2025].

**Non-informative Censoring Assumption**

CPH assumes that censoring is non-informative which means that each
subject has the same risk of experiencing the event regardless of one of
them being censored. Thus, the knowledge of censoring does not result in
any new information being provided [@nahhas2025].

**Linearity Assumption**

CPH assumes the relationship between covariates and the outcome is a
linear relationship [@nahhas2025]. For CPH, the outcome for that
relationship is the log of the hazard rate. This assumption is checked
visually using the Martingale residuals for each covariate
[@nahhas2025]. Martingale residuals are a type of residuals used in
survival analysis that show the discrepancy between the observed and the
expected number of events. The equation is $$
\begin{align*}
\text{Martingale Residuals} = \text{Observed Events} - \text{Expected Events}
\end{align*}
$$

The resulting residuals are examined visually and if they are linear and
appear to have a slope of zero, the linearity assumption is not violated
[@Amini2015]. If a model is being generated with multiple covariates,
multiple Martingale residual plots will need to be generated in order to
verify this assumption for each covariate.

Below is an example plot showing Martingale residuals plotted for a
covariate being tested. From the plot, it is visually clear that the
residuals are linear and appear to have a slope of zero. For this
covariate then, the linearity assumption has not been violated.

```{r,echo=FALSE}
example_martingale <- resid(example_coxmodel, type = "martingale")

plot(example_martingale, 
     main = "Martingale Residuals: Example Covariate",
     ylab = "Martingale Residuals for Example Covariate",
     xlab = "Value Range for Example Covariate")
abline(h = 0, col = "red")
```

**Proportional Hazards Assumption**

The major assumption for CPH is the proportional hazards (PH) assumption
which states that the ratio of hazard rates for any two subjects must be
constant at all times. This means the effect of the covariates must be
constant over time [@Bustan2018]. To test this assumption, the
hypothesis test below is used: $$
\begin{align*}
H_0&: \text{the log hazard ratio for each covariate remains constant over time.} \\
H_1&: \text{the log hazard ratio for each covariate does not remain constant over time}
\end{align*}
$$

To generate the p-value for the hypothesis test, the scaled Schoenfeld
partial residuals are calculated for each covariate. The Schoenfeld
partial residuals are the difference between the value of the covariate
and the expected value of the covariate at the time of failure
[@klein2005]. If the global p-value is $< 0.05$, than the model has at
least one covariate that violates the PH assumption and each individual
covariate p-value will need to be checked. If the global p-value is
$> 0.05$, then the PH assumption holds for all covariates [@nahhas2025].
To visually confirm the PH assumption, the plot of the scaled Schoenfeld
partial residuals for each covariate should be a horizontal line
[@harrison2021].

Violations of the PH assumption can be dealt with in several ways. If
the covariate is categorical, one way is to stratify the covariate which
will generate a separate baseline hazard function for each level of the
covariate [@harrison2021]. This removes the PH assumption for that
covariate, though it will still be assumed for all other covariates in
each level of the stratification [@nahhas2025]. If the covariate is
continuous, one way is to add in a function of time based on the shape
of the hazard ratio plot. This replaces the model's time coefficient
with a function of time as it assumes the covariate varies either
linearly or non-linearly with time [@nahhas2025].

Below is an example plot demonstrating scaled Schoenfeld partial
residuals plotted against time to test the proportional hazards
assumption. While there is some curvature in the line, the residuals are
roughly horizontal indicating proportional hazard over time for this
covariate.

```{r, echo = FALSE}
example_phtest <- cox.zph(example_coxmodel)

plot(example_phtest[1],
     ylab = "Covariate Schoenfeld Residual",
     xlab = "Time")
```

Below is an example of the global value that can be generated for the
whole model. In comparing it with an $\alpha = 0.05$, the covariate does
not meet the proportional hazards assumption as $p = 0.128 < \alpha$ .
However, individually, meal.cal does meet the assumption as
$p = 0.044 < \alpha$ . As such, age would need to be adapted based on
one of the above methods in order to include it in the model.

```{r, echo=FALSE}
multi <- coxph(example_surv_object ~ meal.cal + age, data = lung)
ph_tibble <- cox.zph(multi) %>%
  pluck("table") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  as_tibble()
kable(ph_tibble, format = "markdown")
```

### Model Visualization

Two common model visualizations used for CPH is the forest plot and the
Kaplan-Meier survival curve. The Kaplan-Meier curve assists in
visualizing the initial survival model for the data while the forest
plot assists in visualizing the hazard ratio after generating a model.

**Kaplan Meier Survival Curve**

The Kaplan-Meier (KM) estimator is also known as the Product-Limit
estimator and was proposed by Kaplan and Meier in 1958. The estimator
can be defined as

$$
\hat{S}(t) = \begin{cases}
1 \qquad \qquad \qquad \: \text{if } \; t< t_1,\\
\prod_{t_\leq t}[1 - \frac{d_j}{Y_i}], \quad\text{if} \; t_1 \leq t
\end{cases}
$$ {#eq-km} where,

-   $d_i$ is the number of events at time $t_i$
-   $Y_i$ is the number of individuals who are risk at time $t_i$
    [@klein2005]

KM is a non-parametric estimate which means it makes no assumption of
the shape of the base survival function [@nahhas2025] and is considered
to be well defined up until the largest observed study time $t_{max}$
[@klein2005]. The survival curve provides a visualization of the KM
estimator and are important when modeling survival data because it
demonstrates the time where the event being modeled is expected to
occur.

Below is an example survival curve showing survival probabilities over
time. The line represents the median survival probability with the red
area around it showing the 95% confidence interval for the values. The
curve can be interpreted as showing the probability of event would be
expected to happen around a time of 300 where the survival probability
is below 50% [@Kuitunen2021].

```{r, echo=FALSE}
example_curve <- survfit(example_coxmodel)

ggsurvplot(example_curve,
           data = lung,
           title = "Example Survival Curve",
           xlab = "Time",
           ylab = "Survival Probability",
           legend = "none")
```

**Forest Plots**

Forest plots can be used to visualize the effects of each covariate in
the model on the hazard ratio. The resulting plot contains each
covariate on the y axis, with the estimated effect on the hazard ratio
on the the x axis. The plot contains whiskers demonstrating a 95%
confidence interval for the effect. A positive effect indicates a
positive correlation with the hazard with a higher number signifying a
more severe effect on the hazard ratio.

An example forest plot is shown below plotting the hazard ratio for each
covariate in the model. The point represents the calculated hazard ratio
and the whiskers show the 95% confidence interval.

```{r, echo=FALSE,warning=FALSE}
forest <- coxph(example_surv_object ~ age + sex, data = lung)

plot_model(forest,
           dot.size = 1,
           line.size = 1,
           colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")

```

### Evaluation

Evaluation of the accuracy of the CPH model is done using the
concordance index which is used to measure the amount of agreement
between two variables. Specifically, the value looks at concordant pairs
and disconcordant pairs. A concordant pair is when either $x_i < x_j$
and $y_i < y_j$ or $x_i > x_j$ and $y_i > y_j$. A discordant pair is
when either $x_i$ or $y_i$ are not in the same place such as $x_i < x_j$
but $y_j < y_i$ [@Therneau2017]. In terms of survival, this can be
thought of as examining when the failure event occurs. If two subjects,
A and B, are compared with subject A having a higher risk, the pair
would be considered concordant if subject A does have the failure event
occur before subject B.

The equation for concordance with CPH is

$$
C =\frac{c + \frac{t_x}{2}}{c + d + t_x}
$$ {#eq-concordance}

where,

-   $c$ is the count of pairs that are concordant
-   $d$ is the count of pairs that are discordant
-   $t_x$ are the pairs tied to the predictor $x$ [@Therneau2017]

The concordance index will produce a value between 0 and 1. A value of 1
means all pairs are correctly ordered and a value 0 being the
alternative with no pairs correctly ordered. Any values between 0 and 1
indicate how accurate the CPH model is with the data [@Therneau2017].

### Survival Prediction

CPH can be used to predict the survival probability at a specific time
$S(t|X=x)$, and the hazard ratio for an individual when compared to a
reference individual $\frac{h(t|X=x)}{h(t|X=x_{ref}}$ [@nahhas2025]. If
the resulting probability is greater than or equal to 50%, it is assumed
the event has not occurred. If the resulting probability is less than
50%, it is assumed the event has occurred. It is also possible to
generate a plot of the estimated survival curves for all values of $t$
that are desired.

## Analysis and Results

### Data Structure, Exploration, and Visualization

Though CPH is typically used with health data, it does have applications
in other fields. This paper will study the survivability of a NASA
aircraft engine using data provided by NASA for the study on propagation
modeling [@saxena2008]. In particular, this paper will be examining the
data from the engine make two which has a training dataset and a testing
dataset.

**Data Structure**

Each engine in the NASA data has an unknown amount of wear,
manufacturing variation, and sensor noise which will impact the survival
time. In the training dataset, each engine is operating normally at the
beginning of the time series, will develop a fault, and experience
failure at some point. All engines will have failed in the training
dataset. The conditions the engines are subjected to are represented by
three operational setting fields and twenty-one sensor measurement
fields. In the testing dataset, none of the engines have experienced
failure [@saxena2008].

A column indicating status is needed for both the training and testing
datasets. The value 0 will be used to indicate if the machine is still
working and the value 1 will be used for the last cycle before the
engine fails. Both values will appear in the training dataset as all
engines in that dataset will eventually fail. The testing dataset will
only have the value of 0 as none of the machines have failed in that
dataset.

Below are tables showing the structure of the training and testing data
after the transformations described above.

```{r}
testurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/test_FD002.txt'

test <- read.delim(testurl, header = TRUE, sep = '') %>%
  mutate(status = 0,
         id = id + 260)

trainurl <- 'https://raw.githubusercontent.com/JR-87/capstone4ds_reed/refs/heads/main/train_FD002.txt'

train <- read.delim(trainurl, header = TRUE, sep = '') %>%
  group_by(id) %>%
  mutate(status = if_else(row_number() == n(), 1, 0)) %>%
  ungroup() 

data_all <- rbind(train, test) 


kable(head(data_all, n = 5), format = "markdown", caption = 'NASA Aircraft Engine Data')
```

**Data Visualization**

There are 260 engines in the training data. The histogram shows that the
survival times of the engines are normally distributed and the box plot
shows there six outliers in the dataset. The engines have a median
survival time of 199 cycles with a standard deviation of 46.8. The
maximum number of cycles an engine lasted was 378 while the minimum
number of cycles an engine lasted was 128.

```{r, echo = FALSE}
train_grouped <- train %>% 
  group_by(id) %>%
  slice_max(time)

data_grouped <- data_all %>%
  group_by(id) %>%
  slice_max(time) 


summarymetrics <- data.frame(c("Minimum", "Median", "Mean", "Standard Deviation", "Maximum"),
                             c(min(train_grouped$time), 
                               median(train_grouped$time),
                               mean(train_grouped$time),
                               sd(train_grouped$time),
                               max(train_grouped$time)))

colnames(summarymetrics) <- c("Metric", "Value")
summarymetrics$Value <- round(summarymetrics$Value, digits = 2)
kable(summarymetrics, format = "markdown")

```

```{r, echo=FALSE}
Histogram <- ggplot(data = train_grouped,
       aes(x = time)) +
  geom_histogram(binwidth = 5,
                 fill = "grey")+
  labs(x = "Survival Time (Iterations)",
       y = "Frequency")+
  theme_bw()

box <- ggplot(data = train_grouped,
                  aes(y = time))+
  geom_boxplot(fill = "gray",
               color = "black")+
  ylab("Time (Iterations)")+
  theme_bw()


grid.arrange(Histogram,box,ncol = 2, top = "Distribution of Engine Longevity in Training Data")

```

To determine the initial survival function, the Kaplan-Meier survival
curve was generated and is shown below. The graph visualizes the
survival curve and the information that was gathered through the
histogram.

```{r}
t <- as.matrix(train_grouped[, "time"])
s <- as.matrix(train_grouped[, "status"])

km_fit <- survfit(Surv(t, s) ~ 1)

autoplot(km_fit) + theme_bw()
```

### Creating Cox Proportional Hazards Model

**Covariate Selection**

Based on the information provided by NASA on their data, there are
various sensors and operational setting fields that do not impact the
survival rate of an engine. To determine which covariates will impact
the survival probability, the below univariate test was run. The
covariates in which the p-value is $< 0.05$ will be considered for the
CPH models while the other covariates will be excluded.

```{r}
covariates <- c("os1", "os2", "os3", "sm1", "sm2", "sm3", "sm4", "sm5", "sm6", "sm7",
                "sm8", "sm9", "sm10", "sm11", "sm12", "sm13", "sm14", "sm15", "sm16",
                "sm17", "sm18", "sm19", "sm20", "sm21")

univ_formulas <- sapply(covariates,
                        function(x) as.formula(paste('Surv(time, status)~', x)))

univ_models <- lapply( univ_formulas, function(x){coxph(x, data = data_grouped)})

# Extract data
univ_results <- lapply(univ_models,
                       function(x){
                          x <- summary(x)
                          p.value<-signif(x$wald["pvalue"], digits=2)
                          wald.test<-signif(x$wald["test"], digits=2)
                          beta<-signif(x$coef[1], digits=2);#coefficient beta
                          HR <-signif(x$coef[2], digits=2);#exp(beta)
                          HR.confint.lower <- signif(x$conf.int[,"lower .95"], 2)
                          HR.confint.upper <- signif(x$conf.int[,"upper .95"],2)
                          HR <- paste0(HR, " (",
                                       HR.confint.lower, "-", HR.confint.upper, ")")
                          res<-c(beta, HR, wald.test, p.value)
                          names(res)<-c("beta", "HR (95% CI for HR)", "wald.test",
                                        "p.value")
                          return(res)
                         })
kable(as.data.frame(univ_results))
```

Based on the above test, the covariates that will be considered for the
CPH models are os1, os3, sm1, sm5, sm6, sm7, sm11, sm12, sm13, sm14,
sm19, sm20, and sm21 which is fourteen out of twenty-four possible
covariates.

**Generating Models**

Generation of all CPH models will be done using R, specifically the R
package `survival`. To generate the CPH model with properly formatted
survival data, a survival object is created by running
`Surv(time, event)` where `time` is the time field and `event` is the
event field. To generate the actual model, the survival object is then
applied to the function `coxph(survival object ~ x, data)` where `x`
represents one or multiple covariate(s) and `data` is the survival data
that is being modeled.[@R-base].

The table below provides the model number, the covariates used, and the
concordance index. The concordance index generates a value to determine
which model is the most accurate with the provided covariates. After
determining the most accurate model, the CPH assumptions will be tested.

```{r}
surv_object <- Surv(data_grouped$time, data_grouped$status)

cox1 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm1 + sm5 + sm6 + sm7 + sm11 + sm12 + sm13 + sm14 + sm19 + sm20 + sm21)

cox2 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm1 + sm5)

cox3 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm1 + sm5 + sm6 + sm7 + sm13 + sm14 + sm19 + sm21)

cox4 <- coxph(data = data_grouped, surv_object ~ sm5 + sm6 + sm7 + sm11 + sm12 + sm13 + sm14 + sm19 + sm20 + sm21)

cox5 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm1 + sm5  + sm7 + sm11 + sm12 + sm13 + sm19 + sm20 )

cox6 <- coxph(data = data_grouped, surv_object ~ os1  + sm1 + sm5  + sm7 + sm11 + sm12 + sm13 + sm19  + sm21)

cox7 <- coxph(data = data_grouped, surv_object ~ os1  + sm13 + sm14 + sm19 + sm20)

cox8 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm21)

cox9 <- coxph(data = data_grouped, surv_object ~ os1 + os3 + sm5 + sm6 + sm12 + sm13  + sm19 + sm20 + sm21)

cox10 <- coxph(data = data_grouped, surv_object ~  os3 + sm1 + sm5 + sm6  + sm11 + sm12 + sm13  + sm19 + sm20 + sm21)


```

```{r}
concordance_results <- data.frame(c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", 
                                    "Model 6", "Model 7", "Model 8", "Model 9", "Model 10"), 
                   c("os1, os3, sm1, sm2, sm5, sm6, sm7, sm11, sm12, sm13, sm14, sm19, sm20, sm21", 
                     "os1, os3, sm1, sm2, sm5", 
                     "os1, os3, sm1, sm5, sm6, sm7, sm13, sm14, sm19, sm21", 
                     "sm5, sm6, sm7, sm11, sm12, sm13, sm14, sm19, sm20, sm21", 
                     "os1, os3, sm1, sm2, sm5, sm7, sm11, sm12, sm13, sm19, sm20", 
                     "os1, sm1, sm2, sm5, sm7, sm11, sm12, sm13, sm19, sm21",
                     "os1, sm13, sm14, sm19, sm20", 
                     "os1, os3, sm21",
                     "os1, os3, sm2, sm5, sm6, sm12, sm13, sm19, sm20, sm21",
                     "os3, sm1, sm2, sm5, sm6, sm11, sm12, sm13, sm19, sm20, sm21"),
                   c(cox1$concordance[6], cox2$concordance[6], cox3$concordance[6], cox4$concordance[6], cox5$concordance[6], cox6$concordance[6], cox7$concordance[6], cox8$concordance[6], cox9$concordance[6], cox10$concordance[6]))

colnames(concordance_results) <- c("Model", "Covariates", "Concordance Index")


kable(concordance_results, format = "markdown")

```

Model 1 had the highest concordance index and used all of the covariates
that were determined to be significant to the survival of the engine.
The proceeding analysis will be done using model 1. The below tables
provide the summary values from the model.

```{r}
kable(tidy(cox1), format = "markdown")
g <- glance(cox1)
g <- g %>% select(n, nevent, concordance, std.error.concordance, logLik, statistic.log, p.value.log, statistic.wald, p.value.wald, statistic.sc, p.value.sc)
kable(g, format = "markdown")
```

The forest plot for model 1 is shown below. The covariates that are
closest to the value of one have a hazard rate that has less effect on
the calculated hazard ratio for the entire model.

```{r}
plot_model(cox1,
           dot.size = 2,
           line.size = 1,
           colors = "red")+
  theme_bw()+
  labs(title = "Estimated Effects of Covariates on Hazard Ratios")+
  ylab(label = "Covariates")+
  xlab(label = "Estimated Effect on Hazard Ratio")
```

### Checking Assumptions

After determining the model to use with the covariates, the CPH
assumptions need to be tested to confirm the model is a valid CPH model.
The model may have a high concordance index, but it may not be valid for
CPH to use to predict the survival probability. If any of the
assumptions for the model are not true, the model will need to be
modified.

**Independence Assumption**

The survival times for each individual engine in the training data are
independent of each other. The failure of one engine does not impact the
failure of another so this assumption is met.

**Non-informative Censoring Assumption**

The training dataset does not contain censored data as the documentation
available at the datasetâ€™s source clarifies all engines in the training
data have experienced the desired event of failure at the end of each
time series. As such, this assumption is met.

**Linearity Assumption**

To check the linearity assumption, the residuals of the model are needed
which can be generated using the `resid` function in R and assigning the
type to be martingale (`resid(type = "martingale")` ). This will create
a vector of residuals that can be plotted against the range of values
for each covariate.

The plots of the Martingale residuals vs the range of values for each
covariate is shown below. For each covariate, there is no clear slop
indicating the linearity assumption is true for the covariates in the
model.

```{r}
par(mfrow = c(4,4),
      mar = c(2,2,4,1))

martingale <- resid(cox1, type = "martingale")

plot(data_grouped$os1, martingale, main = "Martingale Residuals: os1")
abline(h = 0, col = "red")

plot(data_grouped$os2, martingale, main = "Martingale Residuals: os2")
abline(h = 0, col = "red")

plot(data_grouped$sm1, martingale, main = "Martingale Residuals: sm1")
abline(h = 0, col = "red")

plot(data_grouped$sm2, martingale, main = "Martingale Residuals: sm2")
abline(h = 0, col = "red")

plot(data_grouped$sm5, martingale, main = "Martingale Residuals: sm5")
abline(h = 0, col = "red")

plot(data_grouped$sm6, martingale, main = "Martingale Residuals: sm6")
abline(h = 0, col = "red")

plot(data_grouped$sm7, martingale, main = "Martingale Residuals: sm7")
abline(h = 0, col = "red")

plot(data_grouped$sm11, martingale, main = "Martingale Residuals: sm11")
abline(h = 0, col = "red")

plot(data_grouped$sm12, martingale, main = "Martingale Residuals: sm12")
abline(h = 0, col = "red")

plot(data_grouped$sm13, martingale, main = "Martingale Residuals: sm13")
abline(h = 0, col = "red")

plot(data_grouped$sm14, martingale, main = "Martingale Residuals: sm14")
abline(h = 0, col = "red")

plot(data_grouped$sm20, martingale, main = "Martingale Residuals: sm20")
abline(h = 0, col = "red")

plot(data_grouped$sm21, martingale, main = "Martingale Residuals: sm21")
abline(h = 0, col = "red")
```

**Proportional Hazards Assumption**

The `cox.zph` function can be used to check the proportional hazards
assumption. As mentioned above, the function calculates p values for
each covariate. The global p-value will first be compared to
$\alpha = 0.05$. If that p-value is $<\alpha$, then at least one
covariate violates the PH assumption and the model will need to be
adapted.

The output below shows the p-values for the hypothesis test and
Schoenfeld residuals. The global p-value is $< \alpha$ so at least one
covariate violates the PH assumption. Examining each individual
covariate through both p-values and the plot of the Schoenfeld residuals
shows that the covariates os1, os3, sm1, sm5, sm13, and sm14 all violate
the PH assumption.

```{r}
cph_ph <- cox.zph(cox1) %>%
  pluck("table") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  as_tibble()
kable(cph_ph, format = "markdown")
```

```{r}
# Function to put ph_plots on one visual
create_ph_plots <- function(coxmodel, row, col){
  # Function takes argument that is a cox model from coxph()
  
  phresults <- cox.zph(coxmodel)

  # Define dimensions of visual
  par(mfrow = c(row, col),
      mar = c(2,2,4,1))


  # Loop through each covariate creating a plot and adding it to the phplot list
  for (i in 1:(length(phresults$table[,1])-1)){
    phplots <- list()
    phplots[i] <- plot(phresults[i], # Create plot for each iteration
                       main = rownames(phresults$table)[i]) # Title of each plot is the rowname from coxmodel$table
  
  }
  mtext("Schoenfeld Residuals vs. Time for Covariates", side = 3, line = -1.5, outer = TRUE, cex = 1) # Title for Visual
  par(mfrow = c(1,1)) # Reset plotting area
}

create_ph_plots(cox1, 3, 5)
```

### Adjusting the Model

The results of the above assumptions demonstrated that several
covariates violate the PH assumption. As such, the model will be
recreated by removing the covariates that violate the PH assumption.
After recreating the model, the PH assumption and the linearity
assumption will be tested again.

The table below demonstrates the new model information which has seven
covariates: sm2, sm5, sm7, sm11, sm12, sm20, and sm21.

```{r}
cox1.1 <- coxph(data = data_grouped,Surv(time, status) ~ sm2 + sm5 + sm7 + sm11 + sm12 + sm20 + sm21)

kable(tidy(cox1.1), format = "markdown")
g <- glance(cox1.1)
g <- g %>% select(n, nevent, concordance, std.error.concordance, logLik, statistic.log, p.value.log, statistic.wald, p.value.wald, statistic.sc, p.value.sc)
kable(g, format = "markdown")

```

The output below shows the p-values for the new model's PH assumption
hypothesis test and Schoenfeld residuals. The global p-value is
$> \alpha$ so the PH assumption has been met for the model even though
the covariate sm5 has an individual p-value of $< \alpha$. As such, this
new model does not violate the PH assumption and the analysis can
continue.

```{r}
ph_2 <- cox.zph(cox1.1) %>%
  pluck("table") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("variable") %>%
  as_tibble()

kable(ph_2, format = "markdown")

create_ph_plots(cox1.1, 3, 5)

```

Since a new model was generated, the below plots confirm that the
linearity assumption is still met for this model.

```{r}

par(mfrow = c(3,3),
      mar = c(2,2,4,1))

martingale <- resid(cox1.1, type = "martingale")


plot(data_grouped$sm2, martingale, main = "Martingale Residuals: sm2")
abline(h = 0, col = "red")

plot(data_grouped$sm5, martingale, main = "Martingale Residuals: sm5")
abline(h = 0, col = "red")

plot(data_grouped$sm7, martingale, main = "Martingale Residuals: sm7")
abline(h = 0, col = "red")

plot(data_grouped$sm11, martingale, main = "Martingale Residuals: sm11")
abline(h = 0, col = "red")

plot(data_grouped$sm12, martingale, main = "Martingale Residuals: sm12")
abline(h = 0, col = "red")

plot(data_grouped$sm20, martingale, main = "Martingale Residuals: sm20")
abline(h = 0, col = "red")

plot(data_grouped$sm21, martingale, main = "Martingale Residuals: sm21")
abline(h = 0, col = "red")


```

### Model Applications and Predictions

The model created can be used to calculate several relevant metrics when
predicting remaining time for the engines until expected failure.
Predictions will be made on the largest value for time for each
individual engine.

#### Model Coefficients

The CPH model created produced coefficients for each covariate
indicating the quantitative effect on the resulting hazard rate. The
coefficients are shown below.

```{r}
coef <- data.frame(CoefficientValue = cox1.1$coefficients)
kable(coef, format = "markdown")
```

#### Hazard Rate Calculation

The coefficients above can be used to calculate the hazard rate at time
$t$. The hazard rate will be calculated for each engine at the engines
max time value.

The engines with the higher hazard rates are at a higher risk of
experiencing failure.

```{r}
data_grouped_reduced <- data_grouped %>% select(id, time, sm2, sm5, sm7, sm11, sm12, sm20, sm21, status)


data_grouped_reduced$HazardRate <- predict(cox1.1,
        newdata = data_grouped_reduced,
        type = "risk")


```

#### Cumulative Hazard Calculation

The cumulative hazard represents the total hazard accumulated for the
individual over time and like the hazard rate, is another measure that
can be used to estimate the risk for the individual at a point in time.
The cumulative hazard for each individual is shown below. Higher values
represent a higher chance of failure.

$H(t) = \int_0^t h(t) dt$ where, $H(t)$ is the cumulative hazard from
time 0 to time $(t)$ $h(t)$ is the hazard rate at time $t$

The cumulative hazard of individuals in the model are shown in the visual below. Higher cumulative hazard indicates a higher level of risk at time `t`.

```{r}
sf <- survfit(cox1.1)

ggsurvplot(fit = sf,
           data = data_grouped_reduced, risk.table = TRUE, fun = "cumhaz")$plot +
  ggtitle('Cumulative Hazard Over Time')

```

#### Survival probability

While cumulative hazard can be used by itself to give an idea of an
individual's risk, it can also be used to calculate a probability of
survival.

Probability Calculation: $S(t) = e^{-H(t)}$ $H(t)$ is the cumulative
hazard up to time $t$.

```{r}
data_grouped_reduced$SurvivalProbability <- predict(cox1.1, type = "survival", newdata = data_grouped_reduced)
kable(head(data_grouped_reduced))

```


The resulting survival curve from the model is shown below. 

```{r}

survtimes <- data.frame(Percent = c("100% Survival", "< 25% Survival,", "< 50% Survival", "< 75% Survival", "<90% Survival"),
                        Time = c(sf$time[sf$lower < 1][1], 
                                    sf$time[sf$lower < .75][1], 
                                    sf$time[sf$lower < .5][1], 
                                    sf$time[sf$lower < .25][1], 
                                    sf$time[sf$lower < .1][1]))

ggsurvplot(fit = sf, data = data_grouped_reduced)$plot +
  ggtitle('Survival Probability Over Time')

```

## Conclusion

The implications of an engine failure are severe, with a possible result including an aircraft crash with a loss of human life and millions of dollars. Based on these implications, there is no acceptable room for failure for aircraft engines. The model created a confidence interval for estimating probabilities at each value of time. The values for time used will be the value where the probability of survival at the lower end of the confidence interval to exercise caution.

```{r}
kable(survtimes)

```

The lower end of the confidence interval for survival probability is shown to hold stable at 100% until `t = 128` with a gradual decrease afterwards. Half of the engines are expected to survive until `t = 221` and 90% of the engines are expected to fail at `t = 316`. These times are reflected by the survival curve shown above. The cumulative hazard over time plot confirms the hazard over time increases. The plot shows a low hazard until `t = 128` with a gradual increase.

Based on these findings, the model can be applied by recommending for NASA not to use engines after 128 iterations have passed. The engines should undergo routine maintenance beforehand and should be evaluated to ensure the probability of survival calculated by the model remains at 100%. All engines should be equipped with sensors for the covariates used and readings should be applied to the model after each use of the engine. The engine should be removed from service if the resulting survival probability is less than 100%.

## References
